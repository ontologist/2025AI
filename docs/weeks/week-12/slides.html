<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Week 12: ML Algorithms</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: linear-gradient(135deg, #2563eb 0%, #7c3aed 100%); color: #333; overflow: hidden; padding-top: 50px; }
        .slide-container { width: 100vw; height: 100vh; display: flex; align-items: center; justify-content: center; position: relative; }
        .slide { display: none; background: white; width: 90%; max-width: 1200px; height: 85vh; border-radius: 20px; box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3); padding: 60px 80px; position: relative; overflow-y: auto; }
        .slide.active { display: block; animation: slideIn 0.5s ease-out; }
        @keyframes slideIn { from { opacity: 0; transform: translateY(30px); } to { opacity: 1; transform: translateY(0); } }
        .slide h1 { font-size: 3em; color: #2563eb; margin-bottom: 20px; text-align: center; }
        .slide h2 { font-size: 2.2em; color: #7c3aed; margin-bottom: 30px; border-bottom: 3px solid #2563eb; padding-bottom: 10px; }
        .slide h3 { font-size: 1.8em; color: #2563eb; margin-top: 30px; margin-bottom: 15px; }
        .slide h4 { font-size: 1.4em; color: #555; margin-top: 20px; margin-bottom: 10px; }
        .slide p { font-size: 1.2em; line-height: 1.8; margin-bottom: 15px; color: #444; }
        .slide ul, .slide ol { font-size: 1.2em; line-height: 1.8; margin-left: 40px; margin-bottom: 20px; }
        .slide li { margin-bottom: 10px; }
        .bilingual { display: grid; grid-template-columns: 1fr 1fr; gap: 40px; margin: 20px 0; }
        .english, .japanese { padding: 20px; border-radius: 10px; }
        .english { background: #dbeafe; border-left: 4px solid #2563eb; }
        .japanese { background: #f3e8ff; border-left: 4px solid #7c3aed; }
        .highlight-box { background: #fef3cd; border-left: 5px solid #f59e0b; padding: 20px; margin: 20px 0; border-radius: 5px; }
        .code-box { background: #f4f4f4; border: 1px solid #ddd; border-radius: 5px; padding: 15px; font-family: 'Courier New', monospace; margin: 15px 0; overflow-x: auto; white-space: pre-wrap; }
        .navigation { position: fixed; bottom: 30px; left: 50%; transform: translateX(-50%); display: flex; gap: 20px; z-index: 1000; }
        .nav-btn { background: white; color: #2563eb; border: 2px solid #2563eb; padding: 12px 30px; font-size: 1.1em; border-radius: 30px; cursor: pointer; transition: all 0.3s; box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2); }
        .nav-btn:hover { background: #2563eb; color: white; transform: translateY(-2px); box-shadow: 0 6px 20px rgba(0, 0, 0, 0.3); }
        .nav-btn:disabled { opacity: 0.5; cursor: not-allowed; }
        .slide-number { position: fixed; top: 70px; right: 30px; background: rgba(255, 255, 255, 0.9); padding: 10px 20px; border-radius: 20px; font-size: 1.1em; color: #2563eb; font-weight: bold; box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1); z-index: 1000; }
        .title-slide { display: flex; flex-direction: column; justify-content: center; align-items: center; text-align: center; height: 100%; }
        .title-slide h1 { font-size: 4em; margin-bottom: 20px; }
        .title-slide .subtitle { font-size: 2em; color: #7c3aed; margin-bottom: 40px; }
        .title-slide .info { font-size: 1.3em; color: #666; margin: 10px 0; }
        .two-column { display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin: 20px 0; }
        .slides-nav { background-color: rgba(255, 255, 255, 0.95); box-shadow: 0 2px 4px rgba(0,0,0,0.1); position: fixed; top: 0; left: 0; right: 0; z-index: 1001; padding: 10px 20px; }
        .slides-nav .container { display: flex; gap: 20px; align-items: center; max-width: 1200px; margin: 0 auto; flex-wrap: wrap; }
        .slides-nav a { color: #1f2937; text-decoration: none; font-weight: 500; transition: color 0.3s ease; font-size: 0.95em; }
        .slides-nav a:hover { color: #2563eb; }
        @media screen and (max-width: 768px) {
            .slide { width: 100vw; height: auto; min-height: 100vh; padding: 20px; border-radius: 0; }
            .bilingual, .two-column { grid-template-columns: 1fr; gap: 15px; }
        }
    </style>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <nav class="slides-nav">
        <div class="container">
            <a href="../../index.html">← Course Home</a>
            <a href="lecture.html">Lecture Notes</a>
            <a href="assignment.html">Assignment</a>
        </div>
    </nav>

    <div class="slide-number" id="slideNumber">Slide 1 / 14</div>

    <div class="slide-container">
        <div class="slide active title-slide">
            <h1>Week 12</h1>
            <p class="subtitle">ML Algorithms<br>機械学習のアルゴリズム</p>
            <p class="info"><strong>Course:</strong> Introduction to AI and Data Science</p>
            <p class="info"><strong>Topics:</strong> Neural Networks Basics, Gradient Descent</p>
        </div>

        <div class="slide">
            <h2>Today's Objectives / 本日の目標</h2>
            <div class="bilingual">
                <div class="english">
                    <h3>What You'll Learn:</h3>
                    <ul>
                        <li>Understand neural network architecture</li>
                        <li>Master gradient descent optimization</li>
                        <li>Learn backpropagation basics</li>
                        <li>Explore deep learning applications</li>
                    </ul>
                </div>
                <div class="japanese">
                    <h3>学ぶこと:</h3>
                    <ul>
                        <li>ニューラルネットワークのアーキテクチャを理解する</li>
                        <li>勾配降下法の最適化を習得する</li>
                        <li>バックプロパゲーションの基礎を学ぶ</li>
                        <li>深層学習の応用を探る</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="slide">
            <h2>What is a Neural Network?</h2>
            <h2>ニューラルネットワークとは？</h2>
            <div class="highlight-box">
                <h3>Inspired by the Human Brain</h3>
                <p><strong>A computing system inspired by biological neural networks in the brain</strong></p>
                <p><strong>脳の生物学的ニューラルネットワークに着想を得たコンピューティングシステム</strong></p>
            </div>
            <div class="code-box">Structure / 構造:

Input Layer → Hidden Layer(s) → Output Layer
入力層      → 隠れ層           → 出力層

Each connection has a weight (strength)
各接続には重み（強度）がある

Neurons activate based on weighted inputs
ニューロンは重み付き入力に基づいて活性化</div>
        </div>

        <div class="slide">
            <h2>Neural Network Components</h2>
            <h2>ニューラルネットワークのコンポーネント</h2>
            <div class="bilingual">
                <div class="english">
                    <h3>Key Parts:</h3>
                    <ul>
                        <li><strong>Neurons (Nodes):</strong> Processing units that receive inputs</li>
                        <li><strong>Weights:</strong> Numbers that control connection strength</li>
                        <li><strong>Bias:</strong> Additional parameter for flexibility</li>
                        <li><strong>Activation Function:</strong> Introduces non-linearity</li>
                        <li><strong>Layers:</strong>
                            <ul>
                                <li>Input: Receives data</li>
                                <li>Hidden: Processes information</li>
                                <li>Output: Makes predictions</li>
                            </ul>
                        </li>
                    </ul>
                </div>
                <div class="japanese">
                    <h3>主要部分:</h3>
                    <ul>
                        <li><strong>ニューロン（ノード）:</strong> 入力を受け取る処理ユニット</li>
                        <li><strong>重み:</strong> 接続の強度を制御する数値</li>
                        <li><strong>バイアス:</strong> 柔軟性のための追加パラメータ</li>
                        <li><strong>活性化関数:</strong> 非線形性を導入</li>
                        <li><strong>層:</strong>
                            <ul>
                                <li>入力: データを受け取る</li>
                                <li>隠れ: 情報を処理</li>
                                <li>出力: 予測を行う</li>
                            </ul>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="slide">
            <h2>Activation Functions</h2>
            <h2>活性化関数</h2>
            <div class="two-column">
                <div>
                    <h3>Common Functions</h3>
                    <h4>一般的な関数</h4>
                    <ul>
                        <li><strong>Sigmoid:</strong> σ(x) = 1/(1+e^-x)<br>Output: 0 to 1</li>
                        <li><strong>ReLU:</strong> max(0, x)<br>Most popular for hidden layers</li>
                        <li><strong>Tanh:</strong> (e^x - e^-x)/(e^x + e^-x)<br>Output: -1 to 1</li>
                        <li><strong>Softmax:</strong> For multi-class output</li>
                    </ul>
                </div>
                <div>
                    <h3>Why Use Them?</h3>
                    <h4>なぜ使うのか？</h4>
                    <ul>
                        <li>Introduce non-linearity</li>
                        <li>非線形性を導入</li>
                        <li>Enable learning complex patterns</li>
                        <li>複雑なパターンの学習を可能に</li>
                        <li>Without them, network = linear regression</li>
                        <li>それらなしでは、ネットワーク = 線形回帰</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="slide">
            <h2>What is Gradient Descent?</h2>
            <h2>勾配降下法とは？</h2>
            <div class="highlight-box">
                <h3>Definition / 定義:</h3>
                <p><strong>An optimization algorithm to minimize error by adjusting weights iteratively</strong></p>
                <p><strong>重みを反復的に調整してエラーを最小化する最適化アルゴリズム</strong></p>
            </div>
            <div class="bilingual">
                <div class="english">
                    <h3>Analogy:</h3>
                    <p>Imagine standing on a mountain in fog. You want to reach the valley (minimum error).</p>
                    <ul>
                        <li>Look around (calculate gradient)</li>
                        <li>Take a step downhill (update weights)</li>
                        <li>Repeat until you reach the bottom</li>
                    </ul>
                    <h4>Learning Rate:</h4>
                    <p>Step size - too big = overshoot, too small = slow</p>
                </div>
                <div class="japanese">
                    <h3>類推:</h3>
                    <p>霧の中の山に立っていると想像してください。谷（最小エラー）に到達したい。</p>
                    <ul>
                        <li>周りを見回す（勾配を計算）</li>
                        <li>下り坂に一歩踏み出す（重みを更新）</li>
                        <li>底に到達するまで繰り返す</li>
                    </ul>
                    <h4>学習率:</h4>
                    <p>ステップサイズ - 大きすぎる = 行き過ぎ、小さすぎる = 遅い</p>
                </div>
            </div>
        </div>

        <div class="slide">
            <h2>Gradient Descent Algorithm</h2>
            <h2>勾配降下法アルゴリズム</h2>
            <div class="code-box">Algorithm Steps / アルゴリズムのステップ:

1. Initialize weights randomly
   重みをランダムに初期化

2. For each iteration:
   各イテレーションで:
   a. Calculate prediction: y_pred = f(X, weights)
      予測を計算
   b. Calculate error/loss: L = (y_true - y_pred)²
      エラー/損失を計算
   c. Calculate gradient: ∂L/∂w
      勾配を計算
   d. Update weights: w = w - learning_rate * gradient
      重みを更新

3. Repeat until convergence
   収束するまで繰り返す</div>
        </div>

        <div class="slide">
            <h2>Types of Gradient Descent</h2>
            <h2>勾配降下法のタイプ</h2>
            <div class="bilingual">
                <div class="english">
                    <h3>Three Variants:</h3>
                    <ul>
                        <li><strong>Batch Gradient Descent:</strong>
                            <ul>
                                <li>Uses ALL training data per update</li>
                                <li>Slow but accurate</li>
                            </ul>
                        </li>
                        <li><strong>Stochastic Gradient Descent (SGD):</strong>
                            <ul>
                                <li>Uses ONE sample per update</li>
                                <li>Fast but noisy</li>
                            </ul>
                        </li>
                        <li><strong>Mini-Batch Gradient Descent:</strong>
                            <ul>
                                <li>Uses small batch (e.g., 32 samples)</li>
                                <li>Best of both worlds - MOST COMMON</li>
                            </ul>
                        </li>
                    </ul>
                </div>
                <div class="japanese">
                    <h3>3つの変種:</h3>
                    <ul>
                        <li><strong>バッチ勾配降下法:</strong>
                            <ul>
                                <li>更新ごとにすべての訓練データを使用</li>
                                <li>遅いが正確</li>
                            </ul>
                        </li>
                        <li><strong>確率的勾配降下法（SGD）:</strong>
                            <ul>
                                <li>更新ごとに1つのサンプルを使用</li>
                                <li>高速だがノイジー</li>
                            </ul>
                        </li>
                        <li><strong>ミニバッチ勾配降下法:</strong>
                            <ul>
                                <li>小さなバッチを使用（例: 32サンプル）</li>
                                <li>両方の長所 - 最も一般的</li>
                            </ul>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="slide">
            <h2>Real-World: Image Recognition (ImageNet)</h2>
            <h2>実世界の例: 画像認識（ImageNet）</h2>
            <div class="highlight-box">
                <p><strong>Application:</strong> Google Photos, Facebook Auto-Tagging</p>
                <p><strong>Link:</strong> <a href="https://www.image-net.org" target="_blank">https://www.image-net.org</a></p>
            </div>
            <div class="bilingual">
                <div class="english">
                    <h3>Deep Neural Networks for Vision:</h3>
                    <ul>
                        <li><strong>Architecture:</strong> Convolutional Neural Networks (CNNs)</li>
                        <li><strong>Layers:</strong> 100+ layers in modern networks</li>
                        <li><strong>Training:</strong> Millions of labeled images</li>
                        <li><strong>Optimization:</strong> Mini-batch gradient descent</li>
                        <li><strong>Accuracy:</strong> Surpassed human performance in 2015</li>
                    </ul>
                    <p><strong>Applications:</strong> Face recognition, medical imaging, autonomous vehicles</p>
                </div>
                <div class="japanese">
                    <h3>視覚のための深層ニューラルネットワーク:</h3>
                    <ul>
                        <li><strong>アーキテクチャ:</strong> 畳み込みニューラルネットワーク（CNN）</li>
                        <li><strong>層:</strong> 最新のネットワークでは100層以上</li>
                        <li><strong>訓練:</strong> 数百万のラベル付き画像</li>
                        <li><strong>最適化:</strong> ミニバッチ勾配降下法</li>
                        <li><strong>精度:</strong> 2015年に人間のパフォーマンスを超えた</li>
                    </ul>
                    <p><strong>応用:</strong> 顔認識、医療画像、自動運転車</p>
                </div>
            </div>
        </div>

        <div class="slide">
            <h2>Backpropagation</h2>
            <h2>バックプロパゲーション</h2>
            <div class="highlight-box">
                <h3>The Learning Algorithm</h3>
                <p><strong>Efficiently calculates gradients for all weights using chain rule</strong></p>
                <p><strong>連鎖律を使用してすべての重みの勾配を効率的に計算</strong></p>
            </div>
            <div class="bilingual">
                <div class="english">
                    <h3>How it Works:</h3>
                    <ol>
                        <li><strong>Forward Pass:</strong> Calculate predictions</li>
                        <li><strong>Calculate Error:</strong> Compare prediction to actual</li>
                        <li><strong>Backward Pass:</strong> Propagate error backwards through network</li>
                        <li><strong>Update Weights:</strong> Using gradient descent</li>
                    </ol>
                    <p><strong>Key Insight:</strong> Error from output layer flows backward to adjust all weights</p>
                </div>
                <div class="japanese">
                    <h3>仕組み:</h3>
                    <ol>
                        <li><strong>順伝播:</strong> 予測を計算</li>
                        <li><strong>エラー計算:</strong> 予測と実際を比較</li>
                        <li><strong>逆伝播:</strong> エラーをネットワークを通じて逆に伝播</li>
                        <li><strong>重み更新:</strong> 勾配降下法を使用</li>
                    </ol>
                    <p><strong>重要な洞察:</strong> 出力層からのエラーが後方に流れてすべての重みを調整</p>
                </div>
            </div>
        </div>

        <div class="slide">
            <h2>Real-World: Language Translation</h2>
            <h2>実世界の例: 言語翻訳</h2>
            <div class="highlight-box">
                <p><strong>Application:</strong> Google Translate</p>
                <p><strong>Link:</strong> <a href="https://translate.google.com" target="_blank">https://translate.google.com</a></p>
            </div>
            <div class="bilingual">
                <div class="english">
                    <h3>Neural Machine Translation:</h3>
                    <ul>
                        <li><strong>Architecture:</strong> Transformer networks (Attention mechanism)</li>
                        <li><strong>Training Data:</strong> Billions of sentence pairs</li>
                        <li><strong>Languages:</strong> Supports 100+ languages</li>
                        <li><strong>Learning:</strong> Gradient descent + backpropagation</li>
                        <li><strong>Improvement:</strong> Continuous learning from user corrections</li>
                    </ul>
                    <p><strong>Impact:</strong> 500M+ daily users, breaking language barriers globally</p>
                </div>
                <div class="japanese">
                    <h3>ニューラル機械翻訳:</h3>
                    <ul>
                        <li><strong>アーキテクチャ:</strong> トランスフォーマーネットワーク（アテンション機構）</li>
                        <li><strong>訓練データ:</strong> 数十億の文ペア</li>
                        <li><strong>言語:</strong> 100以上の言語をサポート</li>
                        <li><strong>学習:</strong> 勾配降下法 + バックプロパゲーション</li>
                        <li><strong>改善:</strong> ユーザー修正から継続的に学習</li>
                    </ul>
                    <p><strong>影響:</strong> 毎日5億人以上のユーザー、世界中で言語の壁を打破</p>
                </div>
            </div>
        </div>

        <div class="slide">
            <h2>Deep Learning vs Traditional ML</h2>
            <h2>深層学習 vs 従来のML</h2>
            <div class="two-column">
                <div>
                    <h3>Deep Learning</h3>
                    <h4>深層学習</h4>
                    <ul>
                        <li><strong>Pros:</strong>
                            <ul>
                                <li>Automatic feature learning</li>
                                <li>自動特徴学習</li>
                                <li>Handles complex patterns</li>
                                <li>複雑なパターンを処理</li>
                                <li>State-of-the-art performance</li>
                                <li>最先端のパフォーマンス</li>
                            </ul>
                        </li>
                        <li><strong>Cons:</strong>
                            <ul>
                                <li>Needs lots of data</li>
                                <li>Computationally expensive</li>
                                <li>Black box (hard to interpret)</li>
                            </ul>
                        </li>
                    </ul>
                </div>
                <div>
                    <h3>Traditional ML</h3>
                    <h4>従来のML</h4>
                    <ul>
                        <li><strong>Pros:</strong>
                            <ul>
                                <li>Works with small data</li>
                                <li>少ないデータで機能</li>
                                <li>Faster training</li>
                                <li>より高速な訓練</li>
                                <li>More interpretable</li>
                                <li>より解釈可能</li>
                            </ul>
                        </li>
                        <li><strong>Cons:</strong>
                            <ul>
                                <li>Manual feature engineering</li>
                                <li>Limited complexity</li>
                                <li>May underperform on complex tasks</li>
                            </ul>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="slide">
            <h2>Real-World: Voice Assistants</h2>
            <h2>実世界の例: 音声アシスタント</h2>
            <div class="highlight-box">
                <p><strong>Applications:</strong> Siri, Alexa, Google Assistant</p>
                <p><strong>Links:</strong> <a href="https://www.apple.com/siri/" target="_blank">Siri</a> | <a href="https://alexa.amazon.com" target="_blank">Alexa</a></p>
            </div>
            <div class="bilingual">
                <div class="english">
                    <h3>Deep Learning for Voice:</h3>
                    <ul>
                        <li><strong>Speech Recognition:</strong> Convert audio to text (Recurrent Neural Networks)</li>
                        <li><strong>Natural Language Understanding:</strong> Interpret meaning (Transformers)</li>
                        <li><strong>Speech Synthesis:</strong> Generate voice responses (WaveNet)</li>
                        <li><strong>Training:</strong> Thousands of hours of speech data</li>
                        <li><strong>Optimization:</strong> Advanced gradient descent variants (Adam optimizer)</li>
                    </ul>
                </div>
                <div class="japanese">
                    <h3>音声のための深層学習:</h3>
                    <ul>
                        <li><strong>音声認識:</strong> 音声をテキストに変換（再帰型ニューラルネットワーク）</li>
                        <li><strong>自然言語理解:</strong> 意味を解釈（トランスフォーマー）</li>
                        <li><strong>音声合成:</strong> 音声応答を生成（WaveNet）</li>
                        <li><strong>訓練:</strong> 数千時間の音声データ</li>
                        <li><strong>最適化:</strong> 高度な勾配降下法の変種（Adamオプティマイザー）</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="slide">
            <h2>Practical Tips for Neural Networks</h2>
            <h2>ニューラルネットワークの実践的なヒント</h2>
            <div class="bilingual">
                <div class="english">
                    <h3>Best Practices:</h3>
                    <ul>
                        <li><strong>Start Simple:</strong> Begin with small networks</li>
                        <li><strong>Normalize Data:</strong> Scale features to similar ranges</li>
                        <li><strong>Choose Right Activation:</strong> ReLU for hidden layers</li>
                        <li><strong>Tune Learning Rate:</strong> Critical for convergence</li>
                        <li><strong>Use Regularization:</strong> Dropout, L2 to prevent overfitting</li>
                        <li><strong>Monitor Training:</strong> Plot loss curves</li>
                        <li><strong>Use Pre-trained Models:</strong> Transfer learning when possible</li>
                    </ul>
                </div>
                <div class="japanese">
                    <h3>ベストプラクティス:</h3>
                    <ul>
                        <li><strong>シンプルから始める:</strong> 小さなネットワークで開始</li>
                        <li><strong>データを正規化:</strong> 特徴を類似範囲にスケール</li>
                        <li><strong>適切な活性化を選択:</strong> 隠れ層にはReLU</li>
                        <li><strong>学習率を調整:</strong> 収束に重要</li>
                        <li><strong>正則化を使用:</strong> 過学習を防ぐためドロップアウト、L2</li>
                        <li><strong>訓練を監視:</strong> 損失曲線をプロット</li>
                        <li><strong>事前訓練モデルを使用:</strong> 可能な場合は転移学習</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="slide">
            <h2>Summary / まとめ</h2>
            <div class="bilingual">
                <div class="english">
                    <h3>Key Takeaways:</h3>
                    <ul>
                        <li>Neural networks: Layers of interconnected neurons with weights</li>
                        <li>Activation functions introduce non-linearity for complex patterns</li>
                        <li>Gradient descent: Optimization algorithm to minimize error</li>
                        <li>Backpropagation: Efficiently calculates gradients using chain rule</li>
                        <li>Real applications: Image recognition, translation, voice assistants</li>
                        <li>Deep learning excels with big data and complex problems</li>
                    </ul>
                </div>
                <div class="japanese">
                    <h3>重要ポイント:</h3>
                    <ul>
                        <li>ニューラルネットワーク: 重みを持つ相互接続されたニューロンの層</li>
                        <li>活性化関数は複雑なパターンのための非線形性を導入</li>
                        <li>勾配降下法: エラーを最小化する最適化アルゴリズム</li>
                        <li>バックプロパゲーション: 連鎖律を使って勾配を効率的に計算</li>
                        <li>実際の応用: 画像認識、翻訳、音声アシスタント</li>
                        <li>深層学習はビッグデータと複雑な問題で優れている</li>
                    </ul>
                </div>
            </div>
            <h3 style="text-align: center; margin-top: 40px;">Next Week / 来週:</h3>
            <p style="text-align: center; font-size: 1.3em;">Reinforcement Learning - N-Armed Bandit Problem</p>
            <p style="text-align: center; font-size: 1.3em;">強化学習 - N本腕バンディット問題</p>
        </div>

    </div>

    <div class="navigation">
        <button class="nav-btn" id="prevBtn" onclick="changeSlide(-1)">◀ Previous</button>
        <button class="nav-btn" id="nextBtn" onclick="changeSlide(1)">Next ▶</button>
    </div>

    <script>
        let currentSlide = 0;
        const slides = document.querySelectorAll('.slide');
        const totalSlides = slides.length;

        function showSlide(n) {
            slides[currentSlide].classList.remove('active');
            currentSlide = (n + totalSlides) % totalSlides;
            slides[currentSlide].classList.add('active');

            document.getElementById('slideNumber').textContent = `Slide ${currentSlide + 1} / ${totalSlides}`;

            document.getElementById('prevBtn').disabled = currentSlide === 0;
            document.getElementById('nextBtn').disabled = currentSlide === totalSlides - 1;
        }

        function changeSlide(direction) {
            showSlide(currentSlide + direction);
        }

        document.addEventListener('keydown', function(event) {
            if (event.key === 'ArrowLeft') {
                changeSlide(-1);
            } else if (event.key === 'ArrowRight' || event.key === ' ') {
                event.preventDefault();
                changeSlide(1);
            } else if (event.key === 'Home') {
                showSlide(0);
            } else if (event.key === 'End') {
                showSlide(totalSlides - 1);
            }
        });

        showSlide(0);
    </script>
</body>
</html>
