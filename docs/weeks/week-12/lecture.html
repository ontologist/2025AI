<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Week 12 Lecture Notes: Neural Networks & ML Algorithms</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            line-height: 1.6;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
        }

        h1 {
            color: #2563eb;
            font-size: 2.5em;
            margin-bottom: 10px;
            text-align: center;
            border-bottom: 4px solid #7c3aed;
            padding-bottom: 20px;
        }

        h2 {
            color: #7c3aed;
            font-size: 2em;
            margin-top: 40px;
            margin-bottom: 20px;
            border-left: 6px solid #2563eb;
            padding-left: 15px;
        }

        h3 {
            color: #2563eb;
            font-size: 1.5em;
            margin-top: 30px;
            margin-bottom: 15px;
        }

        h4 {
            color: #555;
            font-size: 1.2em;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .subtitle {
            text-align: center;
            color: #666;
            font-size: 1.2em;
            margin-bottom: 30px;
        }

        .bilingual {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin: 20px 0;
        }

        .english {
            background: #dbeafe;
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid #2563eb;
        }

        .japanese {
            background: #f3e8ff;
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid #7c3aed;
        }

        .highlight-box {
            background: #fef3cd;
            border-left: 5px solid #f59e0b;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .definition-box {
            background: #e0f2fe;
            border: 2px solid #0ea5e9;
            padding: 20px;
            margin: 20px 0;
            border-radius: 10px;
        }

        .code-box {
            background: #f4f4f4;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 20px;
            font-family: 'Courier New', monospace;
            margin: 20px 0;
            white-space: pre-wrap;
            overflow-x: auto;
        }

        .test-question {
            background: #fce7f3;
            border: 3px solid #ec4899;
            padding: 25px;
            margin: 25px 0;
            border-radius: 10px;
        }

        .test-question h4::before {
            content: "âš ï¸ ";
        }

        ul, ol {
            margin-left: 40px;
            margin-bottom: 20px;
        }

        li {
            margin-bottom: 10px;
        }

        p {
            margin-bottom: 15px;
        }

        .navigation {
            background: #e0e7ff;
            padding: 20px;
            border-radius: 10px;
            margin: 30px 0;
            text-align: center;
        }

        .navigation a {
            display: inline-block;
            margin: 10px;
            padding: 12px 24px;
            background: #2563eb;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            transition: all 0.3s;
        }

        .navigation a:hover {
            background: #7c3aed;
            transform: translateY(-2px);
        }

        .key-terms {
            background: #f0fdf4;
            border-left: 5px solid #10b981;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .study-tip {
            background: #fff7ed;
            border-left: 5px solid #f97316;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        @media (max-width: 768px) {
            .bilingual {
                grid-template-columns: 1fr;
            }

            .container {
                padding: 20px;
            }

            h1 {
                font-size: 2em;
            }

            h2 {
                font-size: 1.6em;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Week 12 Lecture Notes</h1>
        <p class="subtitle">Neural Networks & ML Algorithms<br>ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </p>

        <div class="navigation">
            <a href="../../index.html">â† Course Home</a>
            <a href="../week-11/lecture.html">â† Previous Week</a>
            <a href="slides.html">View Slides</a>
            <a href="assignment.html">Assignment</a>
        </div>

        <h2>ğŸ“š Overview / æ¦‚è¦</h2>
        <div class="bilingual">
            <div class="english">
                <p>This week introduces Neural Networks, the foundation of modern deep learning and AI. We'll explore how artificial neurons work, understand network architectures, and learn about training through backpropagation. We'll also cover Convolutional Neural Networks (CNNs) for computer vision.</p>
                <p><strong>Learning Objectives:</strong></p>
                <ul>
                    <li>Understand the structure of artificial neurons and neural networks</li>
                    <li>Learn how neural networks learn through backpropagation</li>
                    <li>Explore activation functions and their purposes</li>
                    <li>Understand Convolutional Neural Networks (CNNs)</li>
                    <li>Recognize applications of neural networks in real-world problems</li>
                    <li>Compare deep learning with traditional ML algorithms</li>
                </ul>
            </div>
            <div class="japanese">
                <p>ä»Šé€±ã¯ã€ç¾ä»£ã®æ·±å±¤å­¦ç¿’ã¨AIã®åŸºç›¤ã§ã‚ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚äººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ä»•çµ„ã¿ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç†è§£ã—ã€ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹è¨“ç·´ã«ã¤ã„ã¦å­¦ã³ã¾ã™ã€‚ã¾ãŸã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã®ãŸã‚ã®ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆCNNï¼‰ã‚‚ã‚«ãƒãƒ¼ã—ã¾ã™ã€‚</p>
                <p><strong>å­¦ç¿’ç›®æ¨™:</strong></p>
                <ul>
                    <li>äººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¨ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹é€ ã‚’ç†è§£ã™ã‚‹</li>
                    <li>ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å­¦ç¿’æ–¹æ³•ã‚’å­¦ã¶</li>
                    <li>æ´»æ€§åŒ–é–¢æ•°ã¨ãã®ç›®çš„ã‚’æ¢ã‚‹</li>
                    <li>ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆCNNï¼‰ã‚’ç†è§£ã™ã‚‹</li>
                    <li>å®Ÿä¸–ç•Œã®å•é¡Œã«ãŠã‘ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¿œç”¨ã‚’èªè­˜ã™ã‚‹</li>
                    <li>æ·±å±¤å­¦ç¿’ã¨å¾“æ¥ã®MLã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ¯”è¼ƒã™ã‚‹</li>
                </ul>
            </div>
        </div>

        <h2>1. Introduction to Neural Networks / ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¥é–€</h2>

        <div class="definition-box">
            <h3>What is a Neural Network? / ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã¯ï¼Ÿ</h3>
            <p><strong>Neural Network:</strong> A machine learning model inspired by biological neurons in the brain, consisting of interconnected layers of artificial neurons that process information and learn patterns from data.</p>
            <p><strong>ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯:</strong> è„³å†…ã®ç”Ÿç‰©å­¦çš„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«è§¦ç™ºã•ã‚ŒãŸæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ã€æƒ…å ±ã‚’å‡¦ç†ã—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹ç›¸äº’æ¥ç¶šã•ã‚ŒãŸäººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å±¤ã§æ§‹æˆã•ã‚Œã¾ã™ã€‚</p>
        </div>

        <div class="bilingual">
            <div class="english">
                <h3>From Biological to Artificial Neurons</h3>

                <h4>Biological Neuron</h4>
                <ul>
                    <li><strong>Dendrites:</strong> Receive signals from other neurons</li>
                    <li><strong>Cell Body:</strong> Processes incoming signals</li>
                    <li><strong>Axon:</strong> Sends signal to other neurons</li>
                    <li><strong>Synapses:</strong> Connections between neurons</li>
                </ul>

                <h4>Artificial Neuron (Perceptron)</h4>
                <div class="code-box">ARTIFICIAL NEURON STRUCTURE

Inputs (xâ‚, xâ‚‚, xâ‚ƒ...)  â”€â”€â†’  [NEURON]  â”€â”€â†’  Output (y)
    â”‚                           â”‚
    â”‚                           â”‚
    â†“                           â†“
Weights (wâ‚, wâ‚‚, wâ‚ƒ...)    Activation
                            Function

Process:
1. Multiply each input by its weight: xâ‚Ã—wâ‚, xâ‚‚Ã—wâ‚‚, xâ‚ƒÃ—wâ‚ƒ
2. Sum all weighted inputs: Î£(xáµ¢ Ã— wáµ¢)
3. Add bias: z = Î£(xáµ¢ Ã— wáµ¢) + b
4. Apply activation function: y = f(z)
5. Output final value

Example:
Inputs: [2, 3, 1]
Weights: [0.5, 0.3, 0.2]
Bias: 1

z = (2Ã—0.5) + (3Ã—0.3) + (1Ã—0.2) + 1 = 1 + 0.9 + 0.2 + 1 = 3.1
y = activation(3.1)</div>

                <h4>Key Components:</h4>
                <ul>
                    <li><strong>Inputs (x):</strong> Features from data</li>
                    <li><strong>Weights (w):</strong> Learned parameters that determine importance of each input</li>
                    <li><strong>Bias (b):</strong> Allows shifting the activation function</li>
                    <li><strong>Activation Function:</strong> Introduces non-linearity</li>
                    <li><strong>Output (y):</strong> Final prediction or signal</li>
                </ul>
            </div>
            <div class="japanese">
                <h3>ç”Ÿç‰©å­¦çš„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‹ã‚‰äººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¸</h3>

                <h4>ç”Ÿç‰©å­¦çš„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³</h4>
                <ul>
                    <li><strong>æ¨¹çŠ¶çªèµ·:</strong> ä»–ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‹ã‚‰ä¿¡å·ã‚’å—ä¿¡</li>
                    <li><strong>ç´°èƒä½“:</strong> å…¥åŠ›ä¿¡å·ã‚’å‡¦ç†</li>
                    <li><strong>è»¸ç´¢:</strong> ä»–ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«ä¿¡å·ã‚’é€ä¿¡</li>
                    <li><strong>ã‚·ãƒŠãƒ—ã‚¹:</strong> ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³é–“ã®æ¥ç¶š</li>
                </ul>

                <h4>äººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ï¼‰</h4>
                <div class="code-box">äººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ§‹é€ 

å…¥åŠ› (xâ‚, xâ‚‚, xâ‚ƒ...)  â”€â”€â†’  [ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]  â”€â”€â†’  å‡ºåŠ› (y)
    â”‚                           â”‚
    â”‚                           â”‚
    â†“                           â†“
é‡ã¿ (wâ‚, wâ‚‚, wâ‚ƒ...)        æ´»æ€§åŒ–
                            é–¢æ•°

ãƒ—ãƒ­ã‚»ã‚¹:
1. å„å…¥åŠ›ã«ãã®é‡ã¿ã‚’æ›ã‘ã‚‹: xâ‚Ã—wâ‚, xâ‚‚Ã—wâ‚‚, xâ‚ƒÃ—wâ‚ƒ
2. ã™ã¹ã¦ã®é‡ã¿ä»˜ãå…¥åŠ›ã‚’åˆè¨ˆ: Î£(xáµ¢ Ã— wáµ¢)
3. ãƒã‚¤ã‚¢ã‚¹ã‚’è¿½åŠ : z = Î£(xáµ¢ Ã— wáµ¢) + b
4. æ´»æ€§åŒ–é–¢æ•°ã‚’é©ç”¨: y = f(z)
5. æœ€çµ‚å€¤ã‚’å‡ºåŠ›

ä¾‹:
å…¥åŠ›: [2, 3, 1]
é‡ã¿: [0.5, 0.3, 0.2]
ãƒã‚¤ã‚¢ã‚¹: 1

z = (2Ã—0.5) + (3Ã—0.3) + (1Ã—0.2) + 1 = 1 + 0.9 + 0.2 + 1 = 3.1
y = æ´»æ€§åŒ–(3.1)</div>

                <h4>ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ:</h4>
                <ul>
                    <li><strong>å…¥åŠ›ï¼ˆxï¼‰:</strong> ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®ç‰¹å¾´é‡</li>
                    <li><strong>é‡ã¿ï¼ˆwï¼‰:</strong> å„å…¥åŠ›ã®é‡è¦åº¦ã‚’æ±ºå®šã™ã‚‹å­¦ç¿’ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</li>
                    <li><strong>ãƒã‚¤ã‚¢ã‚¹ï¼ˆbï¼‰:</strong> æ´»æ€§åŒ–é–¢æ•°ã‚’ã‚·ãƒ•ãƒˆã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹</li>
                    <li><strong>æ´»æ€§åŒ–é–¢æ•°:</strong> éç·šå½¢æ€§ã‚’å°å…¥</li>
                    <li><strong>å‡ºåŠ›ï¼ˆyï¼‰:</strong> æœ€çµ‚äºˆæ¸¬ã¾ãŸã¯ä¿¡å·</li>
                </ul>
            </div>
        </div>

        <h2>2. Neural Network Architecture / ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h2>

        <div class="definition-box">
            <h3>Multi-Layer Neural Network</h3>
            <div class="code-box">NEURAL NETWORK LAYERS

INPUT LAYER    HIDDEN LAYERS    OUTPUT LAYER
å…¥åŠ›å±¤          éš ã‚Œå±¤            å‡ºåŠ›å±¤

   xâ‚  â—‹           â—‹                â—‹
              â•±   â•±  â•²   â•²      â•±     â•²
   xâ‚‚  â—‹     â—‹        â—‹        â—‹   â†’  yâ‚
              â•²   â•²  â•±   â•±      â•²     â•±
   xâ‚ƒ  â—‹           â—‹                â—‹

   xâ‚„  â—‹     â—‹        â—‹            yâ‚‚

Layer 1       Layer 2   Layer 3   Layer 4
(Features)    (Hidden)  (Hidden)  (Output)

Connections:
- Fully Connected: Each neuron connects to all neurons in next layer
- Weights: Each connection has a learned weight
- Forward Propagation: Data flows left to right</div>
        </div>

        <div class="bilingual">
            <div class="english">
                <h3>Types of Layers</h3>

                <h4>1. Input Layer (å…¥åŠ›å±¤)</h4>
                <ul>
                    <li>Receives raw data features</li>
                    <li>One neuron per feature</li>
                    <li>Example: For image 28Ã—28 pixels = 784 input neurons</li>
                    <li>No computation, just passes data forward</li>
                </ul>

                <h4>2. Hidden Layers (éš ã‚Œå±¤)</h4>
                <ul>
                    <li>Perform computations and feature extraction</li>
                    <li>Can have multiple hidden layers (= "deep" learning)</li>
                    <li>Each layer learns increasingly complex patterns</li>
                    <li>Layer 1: Simple edges and shapes</li>
                    <li>Layer 2: Combinations of edges (corners, curves)</li>
                    <li>Layer 3: Complex patterns (faces, objects)</li>
                </ul>

                <h4>3. Output Layer (å‡ºåŠ›å±¤)</h4>
                <ul>
                    <li>Produces final predictions</li>
                    <li>Number of neurons = number of outputs
                        <ul>
                            <li>Binary classification: 1 neuron (0 or 1)</li>
                            <li>Multi-class: N neurons (one per class)</li>
                            <li>Regression: 1 neuron (continuous value)</li>
                        </ul>
                    </li>
                </ul>

                <h4>Network Depth</h4>
                <ul>
                    <li><strong>Shallow Network:</strong> 1-2 hidden layers</li>
                    <li><strong>Deep Network:</strong> 3+ hidden layers (Deep Learning)</li>
                    <li><strong>Very Deep:</strong> 50-200+ layers (ResNet, GPT models)</li>
                </ul>

                <h4>Why Multiple Layers?</h4>
                <p><strong>Hierarchical Feature Learning:</strong></p>
                <ul>
                    <li>Each layer learns features of increasing complexity</li>
                    <li>Like how humans recognize objects:
                        <ul>
                            <li>Level 1: See edges and colors</li>
                            <li>Level 2: Combine into shapes</li>
                            <li>Level 3: Recognize parts (eyes, nose)</li>
                            <li>Level 4: Identify whole object (face)</li>
                        </ul>
                    </li>
                </ul>
            </div>
            <div class="japanese">
                <h3>å±¤ã®ã‚¿ã‚¤ãƒ—</h3>

                <h4>1. å…¥åŠ›å±¤ (Input Layer)</h4>
                <ul>
                    <li>ç”Ÿã®ãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡ã‚’å—ã‘å–ã‚‹</li>
                    <li>ç‰¹å¾´é‡ã”ã¨ã«1ã¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³</li>
                    <li>ä¾‹: 28Ã—28ãƒ”ã‚¯ã‚»ãƒ«ã®ç”»åƒ = 784å€‹ã®å…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³</li>
                    <li>è¨ˆç®—ãªã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’å‰æ–¹ã«æ¸¡ã™ã ã‘</li>
                </ul>

                <h4>2. éš ã‚Œå±¤ (Hidden Layers)</h4>
                <ul>
                    <li>è¨ˆç®—ã¨ç‰¹å¾´æŠ½å‡ºã‚’å®Ÿè¡Œ</li>
                    <li>è¤‡æ•°ã®éš ã‚Œå±¤ã‚’æŒã¤ã“ã¨ãŒã§ãã‚‹ï¼ˆ=ã€Œæ·±å±¤ã€å­¦ç¿’ï¼‰</li>
                    <li>å„å±¤ãŒã¾ã™ã¾ã™è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’</li>
                    <li>å±¤1: å˜ç´”ãªã‚¨ãƒƒã‚¸ã¨å½¢çŠ¶</li>
                    <li>å±¤2: ã‚¨ãƒƒã‚¸ã®çµ„ã¿åˆã‚ã›ï¼ˆè§’ã€æ›²ç·šï¼‰</li>
                    <li>å±¤3: è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆé¡”ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰</li>
                </ul>

                <h4>3. å‡ºåŠ›å±¤ (Output Layer)</h4>
                <ul>
                    <li>æœ€çµ‚äºˆæ¸¬ã‚’ç”Ÿæˆ</li>
                    <li>ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•° = å‡ºåŠ›æ•°
                        <ul>
                            <li>äºŒå€¤åˆ†é¡: 1ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆ0ã¾ãŸã¯1ï¼‰</li>
                            <li>å¤šã‚¯ãƒ©ã‚¹: Nãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆã‚¯ãƒ©ã‚¹ã”ã¨ã«1ã¤ï¼‰</li>
                            <li>å›å¸°: 1ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆé€£ç¶šå€¤ï¼‰</li>
                        </ul>
                    </li>
                </ul>

                <h4>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ·±ã•</h4>
                <ul>
                    <li><strong>æµ…ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯:</strong> 1-2éš ã‚Œå±¤</li>
                    <li><strong>æ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯:</strong> 3ä»¥ä¸Šã®éš ã‚Œå±¤ï¼ˆæ·±å±¤å­¦ç¿’ï¼‰</li>
                    <li><strong>éå¸¸ã«æ·±ã„:</strong> 50-200ä»¥ä¸Šã®å±¤ï¼ˆResNetã€GPTãƒ¢ãƒ‡ãƒ«ï¼‰</li>
                </ul>

                <h4>ãªãœè¤‡æ•°ã®å±¤ï¼Ÿ</h4>
                <p><strong>éšå±¤çš„ç‰¹å¾´å­¦ç¿’:</strong></p>
                <ul>
                    <li>å„å±¤ãŒè¤‡é›‘ã•ã‚’å¢—ã™ç‰¹å¾´ã‚’å­¦ç¿’</li>
                    <li>äººé–“ãŒã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’èªè­˜ã™ã‚‹æ–¹æ³•ã«ä¼¼ã¦ã„ã‚‹:
                        <ul>
                            <li>ãƒ¬ãƒ™ãƒ«1: ã‚¨ãƒƒã‚¸ã¨è‰²ã‚’è¦‹ã‚‹</li>
                            <li>ãƒ¬ãƒ™ãƒ«2: å½¢çŠ¶ã«çµ„ã¿åˆã‚ã›ã‚‹</li>
                            <li>ãƒ¬ãƒ™ãƒ«3: ãƒ‘ãƒ¼ãƒ„ã‚’èªè­˜ï¼ˆç›®ã€é¼»ï¼‰</li>
                            <li>ãƒ¬ãƒ™ãƒ«4: å…¨ä½“ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è­˜åˆ¥ï¼ˆé¡”ï¼‰</li>
                        </ul>
                    </li>
                </ul>
            </div>
        </div>

        <h2>3. Activation Functions / æ´»æ€§åŒ–é–¢æ•°</h2>

        <div class="key-terms">
            <h3>Why Activation Functions? / ãªãœæ´»æ€§åŒ–é–¢æ•°ï¼Ÿ</h3>
            <p>Without activation functions, a neural network would just be a series of linear transformations, equivalent to a single linear model. Activation functions introduce <strong>non-linearity</strong>, allowing networks to learn complex patterns.</p>
            <p>æ´»æ€§åŒ–é–¢æ•°ãŒãªã‘ã‚Œã°ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ä¸€é€£ã®ç·šå½¢å¤‰æ›ã«ã™ããšã€å˜ä¸€ã®ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã«ãªã‚Šã¾ã™ã€‚æ´»æ€§åŒ–é–¢æ•°ã¯<strong>éç·šå½¢æ€§</strong>ã‚’å°å…¥ã—ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒè¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚</p>
        </div>

        <div class="bilingual">
            <div class="english">
                <h3>Common Activation Functions</h3>

                <h4>1. Sigmoid (ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰)</h4>
                <div class="code-box">Formula: Ïƒ(x) = 1 / (1 + e^(-x))
Output Range: 0 to 1

Graph:     1 ________
          /
         /
    0 __/

Use: Output layer for binary classification
Pros: Smooth, probability interpretation
Cons: Vanishing gradient problem</div>

                <h4>2. ReLU (Rectified Linear Unit)</h4>
                <div class="code-box">Formula: f(x) = max(0, x)
         = x if x > 0
         = 0 if x â‰¤ 0

Graph:      /
           /
    ______/
          0

Use: Hidden layers (most common!)
Pros: Fast, prevents vanishing gradient
Cons: "Dying ReLU" (neurons can die)</div>

                <h4>3. Tanh (Hyperbolic Tangent)</h4>
                <div class="code-box">Formula: tanh(x) = (e^x - e^(-x)) / (e^x + e^(-x))
Output Range: -1 to 1

Graph:  1 ________
          /
    _____/
   -1

Use: Hidden layers
Pros: Zero-centered (better than sigmoid)
Cons: Still has vanishing gradient</div>

                <h4>4. Softmax</h4>
                <div class="code-box">Formula: softmax(xáµ¢) = e^xáµ¢ / Î£e^xâ±¼
Output: Probability distribution (sums to 1)

Example:
Input: [2.0, 1.0, 0.1]
Output: [0.66, 0.24, 0.10]
(66% Class 1, 24% Class 2, 10% Class 3)

Use: Output layer for multi-class classification
Pros: Converts to probabilities
Cons: Only for output layer</div>

                <h4>Choosing Activation Functions:</h4>
                <ul>
                    <li><strong>Hidden Layers:</strong> Use ReLU (default choice)</li>
                    <li><strong>Binary Classification Output:</strong> Use Sigmoid</li>
                    <li><strong>Multi-class Output:</strong> Use Softmax</li>
                    <li><strong>Regression Output:</strong> No activation (linear)</li>
                </ul>
            </div>
            <div class="japanese">
                <h3>ä¸€èˆ¬çš„ãªæ´»æ€§åŒ–é–¢æ•°</h3>

                <h4>1. ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ (Sigmoid)</h4>
                <div class="code-box">å¼: Ïƒ(x) = 1 / (1 + e^(-x))
å‡ºåŠ›ç¯„å›²: 0ã‹ã‚‰1

ã‚°ãƒ©ãƒ•:    1 ________
          /
         /
    0 __/

ç”¨é€”: äºŒå€¤åˆ†é¡ã®å‡ºåŠ›å±¤
é•·æ‰€: æ»‘ã‚‰ã‹ã€ç¢ºç‡è§£é‡ˆ
çŸ­æ‰€: å‹¾é…æ¶ˆå¤±å•é¡Œ</div>

                <h4>2. ReLU (Rectified Linear Unit)</h4>
                <div class="code-box">å¼: f(x) = max(0, x)
    = x if x > 0
    = 0 if x â‰¤ 0

ã‚°ãƒ©ãƒ•:      /
           /
    ______/
          0

ç”¨é€”: éš ã‚Œå±¤ï¼ˆæœ€ã‚‚ä¸€èˆ¬çš„ï¼ï¼‰
é•·æ‰€: é«˜é€Ÿã€å‹¾é…æ¶ˆå¤±ã‚’é˜²ã
çŸ­æ‰€: ã€Œæ­»ã«ã‚†ãReLUã€ï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒæ­»ã¬å¯èƒ½æ€§ï¼‰</div>

                <h4>3. Tanh (åŒæ›²ç·šæ­£æ¥)</h4>
                <div class="code-box">å¼: tanh(x) = (e^x - e^(-x)) / (e^x + e^(-x))
å‡ºåŠ›ç¯„å›²: -1ã‹ã‚‰1

ã‚°ãƒ©ãƒ•:  1 ________
          /
    _____/
   -1

ç”¨é€”: éš ã‚Œå±¤
é•·æ‰€: ã‚¼ãƒ­ä¸­å¿ƒï¼ˆã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã‚ˆã‚Šè‰¯ã„ï¼‰
çŸ­æ‰€: ã¾ã å‹¾é…æ¶ˆå¤±ãŒã‚ã‚‹</div>

                <h4>4. Softmax</h4>
                <div class="code-box">å¼: softmax(xáµ¢) = e^xáµ¢ / Î£e^xâ±¼
å‡ºåŠ›: ç¢ºç‡åˆ†å¸ƒï¼ˆåˆè¨ˆ1ï¼‰

ä¾‹:
å…¥åŠ›: [2.0, 1.0, 0.1]
å‡ºåŠ›: [0.66, 0.24, 0.10]
(66%ã‚¯ãƒ©ã‚¹1ã€24%ã‚¯ãƒ©ã‚¹2ã€10%ã‚¯ãƒ©ã‚¹3)

ç”¨é€”: å¤šã‚¯ãƒ©ã‚¹åˆ†é¡ã®å‡ºåŠ›å±¤
é•·æ‰€: ç¢ºç‡ã«å¤‰æ›
çŸ­æ‰€: å‡ºåŠ›å±¤ã®ã¿</div>

                <h4>æ´»æ€§åŒ–é–¢æ•°ã®é¸æŠ:</h4>
                <ul>
                    <li><strong>éš ã‚Œå±¤:</strong> ReLUã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®é¸æŠï¼‰</li>
                    <li><strong>äºŒå€¤åˆ†é¡å‡ºåŠ›:</strong> ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã‚’ä½¿ç”¨</li>
                    <li><strong>å¤šã‚¯ãƒ©ã‚¹å‡ºåŠ›:</strong> Softmaxã‚’ä½¿ç”¨</li>
                    <li><strong>å›å¸°å‡ºåŠ›:</strong> æ´»æ€§åŒ–ãªã—ï¼ˆç·šå½¢ï¼‰</li>
                </ul>
            </div>
        </div>

        <h2>4. Training Neural Networks: Backpropagation / ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¨“ç·´: ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³</h2>

        <div class="definition-box">
            <h3>How Neural Networks Learn</h3>
            <div class="code-box">TRAINING PROCESS (è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹)

1. FORWARD PROPAGATION (é †ä¼æ’­)
   â”œâ”€ Input data flows through network
   â”œâ”€ Each layer computes: z = Wx + b, then a = activation(z)
   â””â”€ Produce prediction at output

2. CALCULATE LOSS (æå¤±è¨ˆç®—)
   â”œâ”€ Compare prediction to actual label
   â”œâ”€ Loss function measures error
   â””â”€ Example: Mean Squared Error, Cross-Entropy

3. BACKWARD PROPAGATION (é€†ä¼æ’­)
   â”œâ”€ Calculate gradient of loss with respect to each weight
   â”œâ”€ Use chain rule from calculus
   â””â”€ Gradients flow backward through network

4. UPDATE WEIGHTS (é‡ã¿æ›´æ–°)
   â”œâ”€ Adjust weights to reduce loss
   â”œâ”€ w_new = w_old - (learning_rate Ã— gradient)
   â””â”€ Gradient Descent optimization

5. REPEAT
   â””â”€ Iterate through entire dataset multiple times (epochs)</div>
        </definition-box>

        <div class="bilingual">
            <div class="english">
                <h3>Understanding Backpropagation</h3>

                <h4>The Learning Process</h4>
                <p><strong>Goal:</strong> Find optimal weights that minimize prediction error</p>

                <p><strong>Key Concepts:</strong></p>
                <ul>
                    <li><strong>Loss Function:</strong> Measures how wrong predictions are
                        <ul>
                            <li>Classification: Cross-Entropy Loss</li>
                            <li>Regression: Mean Squared Error (MSE)</li>
                        </ul>
                    </li>
                    <li><strong>Gradient:</strong> Direction and magnitude of steepest increase in loss</li>
                    <li><strong>Gradient Descent:</strong> Move in opposite direction of gradient to minimize loss</li>
                    <li><strong>Learning Rate:</strong> How big of a step to take (Î±)
                        <ul>
                            <li>Too large: May overshoot optimal weights</li>
                            <li>Too small: Training is very slow</li>
                            <li>Typical: 0.001 to 0.1</li>
                        </ul>
                    </li>
                </ul>

                <h4>Training Hyperparameters</h4>
                <ul>
                    <li><strong>Batch Size:</strong> Number of samples per gradient update
                        <ul>
                            <li>Small batch (32-64): More updates, noisier</li>
                            <li>Large batch (256-512): Faster, more stable</li>
                        </ul>
                    </li>
                    <li><strong>Epochs:</strong> Complete passes through training data
                        <ul>
                            <li>Too few: Underfitting</li>
                            <li>Too many: Overfitting</li>
                            <li>Typical: 10-100 epochs</li>
                        </ul>
                    </li>
                    <li><strong>Optimizer:</strong> How to update weights
                        <ul>
                            <li>SGD (Stochastic Gradient Descent)</li>
                            <li>Adam (Adaptive Moment Estimation) - popular!</li>
                            <li>RMSprop</li>
                        </ul>
                    </li>
                </ul>
            </div>
            <div class="japanese">
                <h3>ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã®ç†è§£</h3>

                <h4>å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹</h4>
                <p><strong>ç›®æ¨™:</strong> äºˆæ¸¬ã‚¨ãƒ©ãƒ¼ã‚’æœ€å°åŒ–ã™ã‚‹æœ€é©ãªé‡ã¿ã‚’è¦‹ã¤ã‘ã‚‹</p>

                <p><strong>ä¸»è¦æ¦‚å¿µ:</strong></p>
                <ul>
                    <li><strong>æå¤±é–¢æ•°:</strong> äºˆæ¸¬ãŒã©ã‚Œã ã‘é–“é•ã£ã¦ã„ã‚‹ã‹ã‚’æ¸¬å®š
                        <ul>
                            <li>åˆ†é¡: ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±</li>
                            <li>å›å¸°: å¹³å‡äºŒä¹—èª¤å·®ï¼ˆMSEï¼‰</li>
                        </ul>
                    </li>
                    <li><strong>å‹¾é…:</strong> æå¤±ã®æœ€ã‚‚æ€¥ãªå¢—åŠ ã®æ–¹å‘ã¨å¤§ãã•</li>
                    <li><strong>å‹¾é…é™ä¸‹æ³•:</strong> æå¤±ã‚’æœ€å°åŒ–ã™ã‚‹ãŸã‚ã«å‹¾é…ã®åå¯¾æ–¹å‘ã«ç§»å‹•</li>
                    <li><strong>å­¦ç¿’ç‡:</strong> ã©ã‚Œã ã‘å¤§ããªã‚¹ãƒ†ãƒƒãƒ—ã‚’è¸ã‚€ã‹ï¼ˆÎ±ï¼‰
                        <ul>
                            <li>å¤§ãã™ãã‚‹: æœ€é©ãªé‡ã¿ã‚’é€šã‚Šè¶Šã™å¯èƒ½æ€§</li>
                            <li>å°ã•ã™ãã‚‹: è¨“ç·´ãŒéå¸¸ã«é…ã„</li>
                            <li>ä¸€èˆ¬çš„: 0.001ã‹ã‚‰0.1</li>
                        </ul>
                    </li>
                </ul>

                <h4>è¨“ç·´ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h4>
                <ul>
                    <li><strong>ãƒãƒƒãƒã‚µã‚¤ã‚º:</strong> å‹¾é…æ›´æ–°ã”ã¨ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
                        <ul>
                            <li>å°ãƒãƒƒãƒï¼ˆ32-64ï¼‰: ã‚ˆã‚Šå¤šãã®æ›´æ–°ã€ã‚ˆã‚Šãƒã‚¤ã‚ºãŒå¤šã„</li>
                            <li>å¤§ãƒãƒƒãƒï¼ˆ256-512ï¼‰: ã‚ˆã‚Šé€Ÿãã€ã‚ˆã‚Šå®‰å®š</li>
                        </ul>
                    </li>
                    <li><strong>ã‚¨ãƒãƒƒã‚¯:</strong> è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ãªãƒ‘ã‚¹
                        <ul>
                            <li>å°‘ãªã™ãã‚‹: æœªå­¦ç¿’</li>
                            <li>å¤šã™ãã‚‹: éå­¦ç¿’</li>
                            <li>ä¸€èˆ¬çš„: 10-100ã‚¨ãƒãƒƒã‚¯</li>
                        </ul>
                    </li>
                    <li><strong>ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶:</strong> é‡ã¿ã‚’æ›´æ–°ã™ã‚‹æ–¹æ³•
                        <ul>
                            <li>SGDï¼ˆç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•ï¼‰</li>
                            <li>Adamï¼ˆé©å¿œçš„ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆæ¨å®šï¼‰- äººæ°—ï¼</li>
                            <li>RMSprop</li>
                        </ul>
                    </li>
                </ul>
            </div>
        </div>

        <h2>5. Convolutional Neural Networks (CNNs) / ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</h2>

        <div class="definition-box">
            <h3>What is a CNN? / CNNã¨ã¯ï¼Ÿ</h3>
            <p><strong>Convolutional Neural Network:</strong> A specialized neural network architecture designed for processing grid-like data such as images, using convolutional layers that automatically learn spatial hierarchies of features.</p>
            <p><strong>ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯:</strong> ç”»åƒãªã©ã®ã‚°ãƒªãƒƒãƒ‰çŠ¶ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸç‰¹æ®Šãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€ç‰¹å¾´ã®ç©ºé–“çš„éšå±¤ã‚’è‡ªå‹•çš„ã«å­¦ç¿’ã™ã‚‹ç•³ã¿è¾¼ã¿å±¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚</p>
        </div>

        <div class="bilingual">
            <div class="english">
                <h3>CNN Architecture</h3>

                <h4>Why CNNs for Images?</h4>
                <p>Traditional neural networks treat pixels as independent features, ignoring spatial structure. CNNs preserve spatial relationships!</p>

                <div class="code-box">CNN LAYERS

INPUT IMAGE          CONVOLUTIONAL      POOLING         FULLY CONNECTED
å…¥åŠ›ç”»åƒ             ç•³ã¿è¾¼ã¿å±¤          ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤     å…¨çµåˆå±¤

[Image]      â†’    [Feature Maps]  â†’  [Reduced]    â†’   [Dense]  â†’  [Output]
28Ã—28Ã—3           24Ã—24Ã—32           12Ã—12Ã—32         128          10 classes
(RGB)             (32 filters)       (downsample)     (neurons)    (probabilities)

Key Operations:
1. Convolution: Extract features (edges, textures)
2. Pooling: Reduce dimensions, keep important features
3. Flatten: Convert to 1D for classification
4. Dense: Final classification layers</div>

                <h4>Convolutional Layer</h4>
                <ul>
                    <li><strong>Filters (Kernels):</strong> Small matrices that slide over image
                        <ul>
                            <li>Example: 3Ã—3 or 5Ã—5 filter</li>
                            <li>Each filter detects specific feature (edge, corner, texture)</li>
                            <li>Creates feature map showing where feature appears</li>
                        </ul>
                    </li>
                    <li><strong>How Convolution Works:</strong>
                        <ul>
                            <li>Slide filter across image (leftâ†’right, topâ†’bottom)</li>
                            <li>At each position, multiply filter Ã— image patch</li>
                            <li>Sum the products to get one output value</li>
                            <li>Result: Feature map highlighting detected features</li>
                        </ul>
                    </li>
                    <li><strong>Multiple Filters:</strong> Learn different features
                        <ul>
                            <li>Filter 1: Vertical edges</li>
                            <li>Filter 2: Horizontal edges</li>
                            <li>Filter 3: Diagonal patterns</li>
                            <li>Creates multiple feature maps</li>
                        </ul>
                    </li>
                </ul>

                <h4>Pooling Layer</h4>
                <ul>
                    <li><strong>Purpose:</strong> Reduce dimensions while keeping important features</li>
                    <li><strong>Max Pooling:</strong> Take maximum value in each region
                        <ul>
                            <li>Example: 2Ã—2 pooling reduces size by half</li>
                            <li>Keeps strongest activations</li>
                        </ul>
                    </li>
                    <li><strong>Benefits:</strong>
                        <ul>
                            <li>Reduces computation</li>
                            <li>Makes network translation-invariant (object can be anywhere)</li>
                            <li>Prevents overfitting</li>
                        </ul>
                    </li>
                </ul>

                <h4>Typical CNN Architecture</h4>
                <div class="code-box">Input Image
    â†“
[Conv â†’ ReLU â†’ Conv â†’ ReLU â†’ Pool]  â† Block 1
    â†“
[Conv â†’ ReLU â†’ Conv â†’ ReLU â†’ Pool]  â† Block 2
    â†“
[Conv â†’ ReLU â†’ Conv â†’ ReLU â†’ Pool]  â† Block 3
    â†“
Flatten
    â†“
Dense (Fully Connected) â†’ ReLU
    â†“
Dense â†’ Softmax
    â†“
Output (Class Probabilities)</div>
            </div>
            <div class="japanese">
                <h3>CNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h3>

                <h4>ãªãœç”»åƒã«CNNï¼Ÿ</h4>
                <p>å¾“æ¥ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ãƒ”ã‚¯ã‚»ãƒ«ã‚’ç‹¬ç«‹ã—ãŸç‰¹å¾´ã¨ã—ã¦æ‰±ã„ã€ç©ºé–“æ§‹é€ ã‚’ç„¡è¦–ã—ã¾ã™ã€‚CNNã¯ç©ºé–“é–¢ä¿‚ã‚’ä¿æŒã—ã¾ã™ï¼</p>

                <div class="code-box">CNNå±¤

å…¥åŠ›ç”»åƒ             ç•³ã¿è¾¼ã¿å±¤          ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤     å…¨çµåˆå±¤

[ç”»åƒ]       â†’    [ç‰¹å¾´ãƒãƒƒãƒ—]    â†’  [ç¸®å°]       â†’   [å¯†]     â†’  [å‡ºåŠ›]
28Ã—28Ã—3           24Ã—24Ã—32           12Ã—12Ã—32         128          10ã‚¯ãƒ©ã‚¹
(RGB)             (32ãƒ•ã‚£ãƒ«ã‚¿)       (ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒ«) (ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³) (ç¢ºç‡)

ä¸»è¦æ“ä½œ:
1. ç•³ã¿è¾¼ã¿: ç‰¹å¾´ã‚’æŠ½å‡ºï¼ˆã‚¨ãƒƒã‚¸ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ï¼‰
2. ãƒ—ãƒ¼ãƒªãƒ³ã‚°: æ¬¡å…ƒã‚’å‰Šæ¸›ã€é‡è¦ãªç‰¹å¾´ã‚’ä¿æŒ
3. å¹³å¦åŒ–: åˆ†é¡ã®ãŸã‚ã«1Dã«å¤‰æ›
4. å¯†: æœ€çµ‚åˆ†é¡å±¤</div>

                <h4>ç•³ã¿è¾¼ã¿å±¤</h4>
                <ul>
                    <li><strong>ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚«ãƒ¼ãƒãƒ«ï¼‰:</strong> ç”»åƒä¸Šã‚’ã‚¹ãƒ©ã‚¤ãƒ‰ã™ã‚‹å°ã•ãªè¡Œåˆ—
                        <ul>
                            <li>ä¾‹: 3Ã—3ã¾ãŸã¯5Ã—5ãƒ•ã‚£ãƒ«ã‚¿</li>
                            <li>å„ãƒ•ã‚£ãƒ«ã‚¿ãŒç‰¹å®šã®ç‰¹å¾´ã‚’æ¤œå‡ºï¼ˆã‚¨ãƒƒã‚¸ã€ã‚³ãƒ¼ãƒŠãƒ¼ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ï¼‰</li>
                            <li>ç‰¹å¾´ãŒç¾ã‚Œã‚‹å ´æ‰€ã‚’ç¤ºã™ç‰¹å¾´ãƒãƒƒãƒ—ã‚’ä½œæˆ</li>
                        </ul>
                    </li>
                    <li><strong>ç•³ã¿è¾¼ã¿ã®ä»•çµ„ã¿:</strong>
                        <ul>
                            <li>ç”»åƒå…¨ä½“ã«ãƒ•ã‚£ãƒ«ã‚¿ã‚’ã‚¹ãƒ©ã‚¤ãƒ‰ï¼ˆå·¦â†’å³ã€ä¸Šâ†’ä¸‹ï¼‰</li>
                            <li>å„ä½ç½®ã§ã€ãƒ•ã‚£ãƒ«ã‚¿Ã—ç”»åƒãƒ‘ãƒƒãƒã‚’æ›ã‘ã‚‹</li>
                            <li>ç©ã‚’åˆè¨ˆã—ã¦1ã¤ã®å‡ºåŠ›å€¤ã‚’å¾—ã‚‹</li>
                            <li>çµæœ: æ¤œå‡ºã•ã‚ŒãŸç‰¹å¾´ã‚’å¼·èª¿ã™ã‚‹ç‰¹å¾´ãƒãƒƒãƒ—</li>
                        </ul>
                    </li>
                    <li><strong>è¤‡æ•°ã®ãƒ•ã‚£ãƒ«ã‚¿:</strong> ç•°ãªã‚‹ç‰¹å¾´ã‚’å­¦ç¿’
                        <ul>
                            <li>ãƒ•ã‚£ãƒ«ã‚¿1: å‚ç›´ã‚¨ãƒƒã‚¸</li>
                            <li>ãƒ•ã‚£ãƒ«ã‚¿2: æ°´å¹³ã‚¨ãƒƒã‚¸</li>
                            <li>ãƒ•ã‚£ãƒ«ã‚¿3: å¯¾è§’ãƒ‘ã‚¿ãƒ¼ãƒ³</li>
                            <li>è¤‡æ•°ã®ç‰¹å¾´ãƒãƒƒãƒ—ã‚’ä½œæˆ</li>
                        </ul>
                    </li>
                </ul>

                <h4>ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤</h4>
                <ul>
                    <li><strong>ç›®çš„:</strong> é‡è¦ãªç‰¹å¾´ã‚’ä¿æŒã—ãªãŒã‚‰æ¬¡å…ƒã‚’å‰Šæ¸›</li>
                    <li><strong>æœ€å¤§ãƒ—ãƒ¼ãƒªãƒ³ã‚°:</strong> å„é ˜åŸŸã®æœ€å¤§å€¤ã‚’å–ã‚‹
                        <ul>
                            <li>ä¾‹: 2Ã—2ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã§ã‚µã‚¤ã‚ºã‚’åŠåˆ†ã«å‰Šæ¸›</li>
                            <li>æœ€ã‚‚å¼·ã„æ´»æ€§åŒ–ã‚’ä¿æŒ</li>
                        </ul>
                    </li>
                    <li><strong>åˆ©ç‚¹:</strong>
                        <ul>
                            <li>è¨ˆç®—ã‚’å‰Šæ¸›</li>
                            <li>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å¹³è¡Œç§»å‹•ä¸å¤‰ã«ã™ã‚‹ï¼ˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒã©ã“ã«ã‚ã£ã¦ã‚‚è‰¯ã„ï¼‰</li>
                            <li>éå­¦ç¿’ã‚’é˜²ã</li>
                        </ul>
                    </li>
                </ul>

                <h4>å…¸å‹çš„ãªCNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h4>
                <div class="code-box">å…¥åŠ›ç”»åƒ
    â†“
[ç•³è¾¼ â†’ ReLU â†’ ç•³è¾¼ â†’ ReLU â†’ Pool]  â† ãƒ–ãƒ­ãƒƒã‚¯1
    â†“
[ç•³è¾¼ â†’ ReLU â†’ ç•³è¾¼ â†’ ReLU â†’ Pool]  â† ãƒ–ãƒ­ãƒƒã‚¯2
    â†“
[ç•³è¾¼ â†’ ReLU â†’ ç•³è¾¼ â†’ ReLU â†’ Pool]  â† ãƒ–ãƒ­ãƒƒã‚¯3
    â†“
å¹³å¦åŒ–
    â†“
å…¨çµåˆ â†’ ReLU
    â†“
å…¨çµåˆ â†’ Softmax
    â†“
å‡ºåŠ›ï¼ˆã‚¯ãƒ©ã‚¹ç¢ºç‡ï¼‰</div>
            </div>
        </div>

        <h2>6. Real-World Application / å®Ÿä¸–ç•Œã®å¿œç”¨</h2>

        <div class="highlight-box">
            <h3>Facebook: Facial Recognition (DeepFace)</h3>
            <h4>Link: <a href="https://www.facebook.com" target="_blank">https://www.facebook.com</a></h4>

            <div class="bilingual">
                <div class="english">
                    <p><strong>Challenge:</strong> Automatically tag people in photos among billions of users.</p>

                    <p><strong>CNN Architecture - DeepFace:</strong></p>
                    <ul>
                        <li><strong>Network Depth:</strong> 9-layer deep CNN</li>
                        <li><strong>Input:</strong> 3D-aligned face images (152Ã—152 pixels)</li>
                        <li><strong>Layers:</strong>
                            <ul>
                                <li>Convolutional layers: Extract facial features (edges, textures, facial parts)</li>
                                <li>Max pooling layers: Reduce dimensions</li>
                                <li>Fully connected layers: Learn face representations</li>
                                <li>Output: 4096-dimensional face embedding</li>
                            </ul>
                        </li>
                    </ul>

                    <p><strong>Training Data:</strong></p>
                    <ul>
                        <li>4 million facial images</li>
                        <li>4,000 identities</li>
                        <li>Trained to distinguish between different people</li>
                        <li>Uses Softmax for classification across identities</li>
                    </ul>

                    <p><strong>How It Works:</strong></p>
                    <ol>
                        <li><strong>Face Detection:</strong> Locate faces in photo</li>
                        <li><strong>Alignment:</strong> Normalize face position and angle</li>
                        <li><strong>Feature Extraction:</strong> CNN processes aligned face
                            <ul>
                                <li>Layer 1: Detects edges (eyebrows, nose contours)</li>
                                <li>Layer 2-3: Detects facial parts (eyes, mouth)</li>
                                <li>Layer 4-6: Combines features (eye-nose-mouth relationships)</li>
                                <li>Layer 7-9: Creates unique face representation</li>
                            </ul>
                        </li>
                        <li><strong>Comparison:</strong> Compare to known faces in database</li>
                        <li><strong>Identification:</strong> Match to most similar person</li>
                    </ol>

                    <p><strong>Performance:</strong></p>
                    <ul>
                        <li>97.35% accuracy on Labeled Faces in the Wild (LFW) benchmark</li>
                        <li>Approaches human-level performance (97.5%)</li>
                        <li>Can recognize faces across different angles, lighting, expressions</li>
                    </ul>

                    <p><strong>Privacy Note:</strong> Facebook has disabled automatic tagging in many regions due to privacy concerns, but the technology remains highly advanced.</p>
                </div>
                <div class="japanese">
                    <p><strong>èª²é¡Œ:</strong> æ•°åå„„ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸­ã‹ã‚‰å†™çœŸã®äººç‰©ã‚’è‡ªå‹•çš„ã«ã‚¿ã‚°ä»˜ã‘ã™ã‚‹ã€‚</p>

                    <p><strong>CNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ - DeepFace:</strong></p>
                    <ul>
                        <li><strong>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ·±ã•:</strong> 9å±¤ã®æ·±å±¤CNN</li>
                        <li><strong>å…¥åŠ›:</strong> 3Dæ•´åˆ—ã•ã‚ŒãŸé¡”ç”»åƒï¼ˆ152Ã—152ãƒ”ã‚¯ã‚»ãƒ«ï¼‰</li>
                        <li><strong>å±¤:</strong>
                            <ul>
                                <li>ç•³ã¿è¾¼ã¿å±¤: é¡”ã®ç‰¹å¾´ã‚’æŠ½å‡ºï¼ˆã‚¨ãƒƒã‚¸ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ã€é¡”ãƒ‘ãƒ¼ãƒ„ï¼‰</li>
                                <li>æœ€å¤§ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤: æ¬¡å…ƒã‚’å‰Šæ¸›</li>
                                <li>å…¨çµåˆå±¤: é¡”è¡¨ç¾ã‚’å­¦ç¿’</li>
                                <li>å‡ºåŠ›: 4096æ¬¡å…ƒã®é¡”åŸ‹ã‚è¾¼ã¿</li>
                            </ul>
                        </li>
                    </ul>

                    <p><strong>è¨“ç·´ãƒ‡ãƒ¼ã‚¿:</strong></p>
                    <ul>
                        <li>400ä¸‡ã®é¡”ç”»åƒ</li>
                        <li>4,000ã®ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£</li>
                        <li>ç•°ãªã‚‹äººã€…ã‚’åŒºåˆ¥ã™ã‚‹ã‚ˆã†ã«è¨“ç·´</li>
                        <li>ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£å…¨ä½“ã®åˆ†é¡ã«Softmaxã‚’ä½¿ç”¨</li>
                    </ul>

                    <p><strong>ä»•çµ„ã¿:</strong></p>
                    <ol>
                        <li><strong>é¡”æ¤œå‡º:</strong> å†™çœŸå†…ã®é¡”ã‚’è¦‹ã¤ã‘ã‚‹</li>
                        <li><strong>æ•´åˆ—:</strong> é¡”ã®ä½ç½®ã¨è§’åº¦ã‚’æ­£è¦åŒ–</li>
                        <li><strong>ç‰¹å¾´æŠ½å‡º:</strong> CNNãŒæ•´åˆ—ã•ã‚ŒãŸé¡”ã‚’å‡¦ç†
                            <ul>
                                <li>å±¤1: ã‚¨ãƒƒã‚¸ã‚’æ¤œå‡ºï¼ˆçœ‰æ¯›ã€é¼»ã®è¼ªéƒ­ï¼‰</li>
                                <li>å±¤2-3: é¡”ãƒ‘ãƒ¼ãƒ„ã‚’æ¤œå‡ºï¼ˆç›®ã€å£ï¼‰</li>
                                <li>å±¤4-6: ç‰¹å¾´ã‚’çµ„ã¿åˆã‚ã›ã‚‹ï¼ˆç›®-é¼»-å£ã®é–¢ä¿‚ï¼‰</li>
                                <li>å±¤7-9: ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªé¡”è¡¨ç¾ã‚’ä½œæˆ</li>
                            </ul>
                        </li>
                        <li><strong>æ¯”è¼ƒ:</strong> ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®æ—¢çŸ¥ã®é¡”ã¨æ¯”è¼ƒ</li>
                        <li><strong>è­˜åˆ¥:</strong> æœ€ã‚‚é¡ä¼¼ã—ãŸäººç‰©ã«ãƒãƒƒãƒ</li>
                    </ol>

                    <p><strong>ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:</strong></p>
                    <ul>
                        <li>Labeled Faces in the Wildï¼ˆLFWï¼‰ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§97.35%ã®ç²¾åº¦</li>
                        <li>äººé–“ãƒ¬ãƒ™ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆ97.5%ï¼‰ã«è¿‘ã¥ã</li>
                        <li>ç•°ãªã‚‹è§’åº¦ã€ç…§æ˜ã€è¡¨æƒ…ã§é¡”ã‚’èªè­˜ã§ãã‚‹</li>
                    </ul>

                    <p><strong>ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã«é–¢ã™ã‚‹æ³¨æ„:</strong> Facebookã¯ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã®æ‡¸å¿µã‹ã‚‰å¤šãã®åœ°åŸŸã§è‡ªå‹•ã‚¿ã‚°ä»˜ã‘ã‚’ç„¡åŠ¹ã«ã—ã¦ã„ã¾ã™ãŒã€æŠ€è¡“ã¯éå¸¸ã«é«˜åº¦ãªã¾ã¾ã§ã™ã€‚</p>
                </div>
            </div>
        </div>

        <div class="study-tip">
            <h3>Study Tips for Neural Networks</h3>
            <ul>
                <li>Draw a simple neural network with 2-3 layers by hand</li>
                <li>Understand the purpose of each activation function</li>
                <li>Know the difference between forward and backward propagation</li>
                <li>Visualize how convolution filters work on images</li>
                <li>Understand why CNNs are better than regular NNs for images</li>
                <li>Know the trade-offs: more layers = more capacity but harder to train</li>
                <li>Memorize typical CNN architecture pattern: Conv â†’ ReLU â†’ Pool â†’ Repeat â†’ Dense</li>
            </ul>
        </div>

        <h2>ğŸ“ Test Questions / ãƒ†ã‚¹ãƒˆå•é¡Œ</h2>

        <div class="test-question">
            <h4>TEST QUESTION 1: Multiple Choice</h4>
            <p><strong>What is the purpose of an activation function in a neural network?</strong></p>
            <ol type="A">
                <li>To store the network weights</li>
                <li>To introduce non-linearity so the network can learn complex patterns</li>
                <li>To calculate the loss function</li>
                <li>To split data into training and test sets</li>
            </ol>
            <p><strong>Answer:</strong> B - Activation functions introduce non-linearity, allowing networks to learn complex, non-linear patterns.</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 2: Multiple Choice</h4>
            <p><strong>Which activation function is most commonly used in hidden layers of modern neural networks?</strong></p>
            <ol type="A">
                <li>Sigmoid</li>
                <li>ReLU (Rectified Linear Unit)</li>
                <li>Softmax</li>
                <li>Linear</li>
            </ol>
            <p><strong>Answer:</strong> B - ReLU is the default choice for hidden layers because it's fast and prevents vanishing gradient problems.</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 3: Multiple Choice</h4>
            <p><strong>What is the main advantage of CNNs over traditional neural networks for image processing?</strong></p>
            <ol type="A">
                <li>CNNs require less training data</li>
                <li>CNNs preserve spatial relationships in images</li>
                <li>CNNs train faster</li>
                <li>CNNs use less memory</li>
            </ol>
            <p><strong>Answer:</strong> B - CNNs preserve spatial structure through convolution operations, unlike traditional NNs that treat pixels independently.</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 4: Multiple Choice</h4>
            <p><strong>In backpropagation, what does the learning rate control?</strong></p>
            <ol type="A">
                <li>The number of layers in the network</li>
                <li>How much to update weights in each iteration</li>
                <li>The batch size</li>
                <li>The number of epochs</li>
            </ol>
            <p><strong>Answer:</strong> B - The learning rate determines the step size for weight updates during gradient descent.</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 5: Multiple Choice</h4>
            <p><strong>What does a pooling layer in a CNN do?</strong></p>
            <ol type="A">
                <li>Increases the dimensions of feature maps</li>
                <li>Reduces dimensions while keeping important features</li>
                <li>Adds non-linearity</li>
                <li>Classifies the final output</li>
            </ol>
            <p><strong>Answer:</strong> B - Pooling reduces spatial dimensions while preserving the most important features (e.g., max pooling keeps maximum values).</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 6: Short Answer</h4>
            <p><strong>Explain the four main steps of training a neural network (forward propagation, loss calculation, backward propagation, weight update).</strong></p>
            <p><strong>Sample Answer:</strong></p>
            <ol>
                <li><strong>Forward Propagation:</strong> Input data flows through the network layer by layer. Each neuron computes weighted sum of inputs plus bias, then applies activation function. Final layer produces prediction.</li>
                <li><strong>Loss Calculation:</strong> Compare the network's prediction to the actual label using a loss function (e.g., Cross-Entropy for classification, MSE for regression). This measures how wrong the prediction is.</li>
                <li><strong>Backward Propagation:</strong> Calculate the gradient of the loss with respect to each weight using the chain rule. Gradients flow backward through the network from output to input, showing how much each weight contributed to the error.</li>
                <li><strong>Weight Update:</strong> Adjust weights to reduce loss using gradient descent: w_new = w_old - (learning_rate Ã— gradient). This moves weights in the direction that reduces error.</li>
            </ol>
            <p>This process repeats for many iterations until the network learns optimal weights.</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 7: Short Answer</h4>
            <p><strong>Compare ReLU, Sigmoid, and Softmax activation functions. When would you use each one?</strong></p>
            <p><strong>Sample Answer:</strong></p>
            <p><strong>ReLU (Rectified Linear Unit):</strong></p>
            <ul>
                <li>Formula: f(x) = max(0, x)</li>
                <li>Output: 0 or positive values</li>
                <li>Use: Hidden layers (most common choice)</li>
                <li>Advantages: Fast, prevents vanishing gradient</li>
            </ul>
            <p><strong>Sigmoid:</strong></p>
            <ul>
                <li>Formula: Ïƒ(x) = 1/(1 + e^(-x))</li>
                <li>Output: 0 to 1 (probability-like)</li>
                <li>Use: Output layer for binary classification</li>
                <li>Advantages: Smooth, interpretable as probability</li>
            </ul>
            <p><strong>Softmax:</strong></p>
            <ul>
                <li>Formula: Converts vector to probability distribution</li>
                <li>Output: Probabilities that sum to 1</li>
                <li>Use: Output layer for multi-class classification</li>
                <li>Advantages: Provides class probabilities</li>
            </ul>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 8: Short Answer</h4>
            <p><strong>Describe how a convolutional layer works in a CNN. Include the role of filters and feature maps.</strong></p>
            <p><strong>Sample Answer:</strong></p>
            <p>A convolutional layer works by sliding small filters (kernels) across an input image to detect specific features.</p>
            <p><strong>Process:</strong></p>
            <ol>
                <li><strong>Filters:</strong> Small matrices (e.g., 3Ã—3) containing learnable weights. Each filter is designed to detect a specific feature like edges, corners, or textures.</li>
                <li><strong>Sliding Operation:</strong> The filter slides across the image from left to right, top to bottom. At each position, it performs element-wise multiplication with the image patch underneath.</li>
                <li><strong>Calculation:</strong> Sum all the products to produce a single output value that indicates how strongly that feature is present at that location.</li>
                <li><strong>Feature Maps:</strong> The collection of all output values creates a feature map showing where the detected feature appears in the image.</li>
                <li><strong>Multiple Filters:</strong> Using multiple filters (e.g., 32 or 64) creates multiple feature maps, each detecting different features.</li>
            </ol>
            <p>This allows CNNs to automatically learn hierarchical features: early layers detect simple edges, later layers combine them into complex patterns.</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 9: Application Question</h4>
            <p><strong>Facebook's DeepFace uses a 9-layer CNN for facial recognition. Explain:</strong></p>
            <p><strong>a) What problem does DeepFace solve?</strong></p>
            <p><strong>b) How do the different layers learn hierarchical features?</strong></p>
            <p><strong>c) Why is a CNN better than a traditional neural network for this task?</strong></p>
            <p><strong>Sample Answer:</strong></p>
            <p><strong>a) Problem:</strong> Automatically identify and tag people in photos from billions of users. The system needs to recognize the same person across different angles, lighting conditions, and facial expressions with high accuracy.</p>
            <p><strong>b) Hierarchical Learning:</strong></p>
            <ul>
                <li><strong>Early Layers (1-3):</strong> Detect simple features like edges, lines, and basic contours (eyebrow curves, nose edges)</li>
                <li><strong>Middle Layers (4-6):</strong> Combine simple features into facial parts (complete eyes, nose shape, mouth)</li>
                <li><strong>Deep Layers (7-9):</strong> Combine facial parts into holistic face representations (spatial relationships between eyes, nose, mouth creating unique face signature)</li>
            </ul>
            <p>Each layer builds upon previous layers to create increasingly complex and person-specific representations.</p>
            <p><strong>c) Why CNN is Better:</strong></p>
            <ul>
                <li><strong>Spatial Invariance:</strong> CNNs can recognize faces regardless of position in image</li>
                <li><strong>Local Patterns:</strong> Convolution filters capture local spatial patterns (eyes, nose) before combining them</li>
                <li><strong>Parameter Sharing:</strong> Same filter can detect eyes anywhere in image, reducing parameters</li>
                <li><strong>Translation Invariance:</strong> Pooling makes recognition robust to small shifts</li>
                <li>Traditional NNs would treat each pixel independently, losing crucial spatial structure of faces</li>
            </ul>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 10: Essay Question</h4>
            <p><strong>Explain neural networks from biological inspiration to modern CNNs. Include:</strong></p>
            <ul>
                <li>How biological neurons inspired artificial neurons</li>
                <li>The structure of a multi-layer neural network</li>
                <li>How networks learn through backpropagation</li>
                <li>Why CNNs were developed and how they differ from standard neural networks</li>
                <li>A real-world application demonstrating CNN capabilities</li>
            </ul>
            <p><strong>Sample Answer:</strong></p>

            <p><strong>Biological Inspiration:</strong></p>
            <p>Artificial neural networks are inspired by biological neurons in the brain. Biological neurons receive signals through dendrites, process them in the cell body, and send output through the axon to other neurons via synapses. Similarly, artificial neurons receive inputs, multiply them by weights (like synapse strength), sum them, add bias, and apply an activation function to produce output. This mimics how neurons fire when stimulation exceeds a threshold.</p>

            <p><strong>Multi-Layer Structure:</strong></p>
            <p>Neural networks consist of layers: an input layer receives data features, hidden layers perform computations and learn representations, and an output layer produces predictions. Each layer contains multiple neurons fully connected to the next layer. Deep networks (3+ hidden layers) can learn hierarchical features: simple patterns in early layers â†’ combinations in middle layers â†’ complex concepts in deep layers. This mirrors how human vision works: seeing edges â†’ shapes â†’ objects.</p>

            <p><strong>Learning Through Backpropagation:</strong></p>
            <p>Networks learn by adjusting weights to minimize prediction errors. The process has four steps: (1) Forward propagation flows data through the network to make predictions. (2) Loss calculation measures prediction error. (3) Backward propagation calculates how much each weight contributed to the error using calculus (chain rule). (4) Weight update adjusts weights in the direction that reduces error using gradient descent. Repeating this over many examples allows the network to learn optimal weights that minimize loss.</p>

            <p><strong>Development of CNNs:</strong></p>
            <p>Traditional neural networks treat input features independently, but images have spatial structure where nearby pixels are related. CNNs were developed to preserve spatial relationships through convolutional layers that slide filters across images to detect local patterns. Pooling layers reduce dimensions while keeping important features. This architecture is specifically designed for grid-like data and automatically learns spatial hierarchies of features without manual feature engineering.</p>

            <p><strong>Real-World Application - Facebook DeepFace:</strong></p>
            <p>Facebook's DeepFace CNN achieves 97.35% accuracy in facial recognition, approaching human-level performance. The 9-layer network processes 152Ã—152 pixel face images through convolutional layers that progressively extract features: edges and textures â†’ facial parts (eyes, nose) â†’ complete face representations. Using 4 million training images of 4,000 people, it learns unique face signatures that enable automatic photo tagging. The CNN excels because convolution preserves spatial face structure, pooling provides position invariance, and hierarchical layers capture both local details and global face patterns. This demonstrates how CNNs can solve complex real-world vision tasks that were impossible for traditional algorithms.</p>

            <p><strong>Conclusion:</strong> From biological inspiration to specialized architectures like CNNs, neural networks have evolved to tackle increasingly complex problems, with applications spanning computer vision, natural language processing, and beyond.</p>
        </div>

        <h2>ğŸ¯ Key Takeaways / é‡è¦ãƒã‚¤ãƒ³ãƒˆ</h2>

        <div class="highlight-box">
            <h3>Remember These Core Concepts:</h3>
            <ul>
                <li><strong>Artificial Neuron:</strong> Inputs Ã— Weights + Bias â†’ Activation Function â†’ Output</li>
                <li><strong>Network Structure:</strong> Input Layer â†’ Hidden Layers â†’ Output Layer</li>
                <li><strong>Activation Functions:</strong> ReLU (hidden), Sigmoid (binary output), Softmax (multi-class)</li>
                <li><strong>Training:</strong> Forward Prop â†’ Loss â†’ Backward Prop â†’ Update Weights</li>
                <li><strong>CNNs:</strong> Convolution (feature extraction) + Pooling (dimension reduction)</li>
                <li><strong>Hierarchical Learning:</strong> Simple features â†’ Complex patterns</li>
                <li><strong>Real-World:</strong> Facebook DeepFace (97.35% facial recognition accuracy)</li>
                <li><strong>Deep Learning:</strong> More layers = more capacity but harder to train</li>
            </ul>
        </div>

        <div class="navigation">
            <a href="../../index.html">â† Course Home</a>
            <a href="../week-11/lecture.html">â† Previous Week</a>
            <a href="slides.html">View Slides</a>
            <a href="assignment.html">Assignment</a>
            <a href="../week-13/lecture.html">Next Week â†’</a>
        </div>

        <footer style="margin-top: 50px; padding-top: 20px; border-top: 2px solid #e5e7eb; text-align: center; color: #666;">
            <p>Week 12 Lecture Notes - Introduction to AI and Data Science</p>
            <p>Chukyo University - 2025</p>
        </footer>
    </div>
</body>
</html>