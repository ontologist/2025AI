<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Week 10 Lecture Notes: Supervised Learning Basics</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            line-height: 1.6;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
        }

        h1 {
            color: #2563eb;
            font-size: 2.5em;
            margin-bottom: 10px;
            text-align: center;
            border-bottom: 4px solid #7c3aed;
            padding-bottom: 20px;
        }

        h2 {
            color: #7c3aed;
            font-size: 2em;
            margin-top: 40px;
            margin-bottom: 20px;
            border-left: 6px solid #2563eb;
            padding-left: 15px;
        }

        h3 {
            color: #2563eb;
            font-size: 1.5em;
            margin-top: 30px;
            margin-bottom: 15px;
        }

        h4 {
            color: #555;
            font-size: 1.2em;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .subtitle {
            text-align: center;
            color: #666;
            font-size: 1.2em;
            margin-bottom: 30px;
        }

        .bilingual {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin: 20px 0;
        }

        .english {
            background: #dbeafe;
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid #2563eb;
        }

        .japanese {
            background: #f3e8ff;
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid #7c3aed;
        }

        .highlight-box {
            background: #fef3cd;
            border-left: 5px solid #f59e0b;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .definition-box {
            background: #e0f2fe;
            border: 2px solid #0ea5e9;
            padding: 20px;
            margin: 20px 0;
            border-radius: 10px;
        }

        .code-box {
            background: #f4f4f4;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 20px;
            font-family: 'Courier New', monospace;
            margin: 20px 0;
            white-space: pre-wrap;
            overflow-x: auto;
        }

        .test-question {
            background: #fce7f3;
            border: 3px solid #ec4899;
            padding: 25px;
            margin: 25px 0;
            border-radius: 10px;
        }

        .test-question h4::before {
            content: "âš ï¸ ";
        }

        ul, ol {
            margin-left: 40px;
            margin-bottom: 20px;
        }

        li {
            margin-bottom: 10px;
        }

        p {
            margin-bottom: 15px;
        }

        .navigation {
            background: #e0e7ff;
            padding: 20px;
            border-radius: 10px;
            margin: 30px 0;
            text-align: center;
        }

        .navigation a {
            display: inline-block;
            margin: 10px;
            padding: 12px 24px;
            background: #2563eb;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            transition: all 0.3s;
        }

        .navigation a:hover {
            background: #7c3aed;
            transform: translateY(-2px);
        }

        .key-terms {
            background: #f0fdf4;
            border-left: 5px solid #10b981;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .study-tip {
            background: #fff7ed;
            border-left: 5px solid #f97316;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        @media (max-width: 768px) {
            .bilingual {
                grid-template-columns: 1fr;
            }

            .container {
                padding: 20px;
            }

            h1 {
                font-size: 2em;
            }

            h2 {
                font-size: 1.6em;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Week 10 Lecture Notes</h1>
        <p class="subtitle">Supervised Learning Basics<br>æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®åŸºç¤</p>

        <div class="navigation">
            <a href="../../index.html">â† Course Home</a>
            <a href="../week-09/lecture.html">â† Previous Week</a>
            <a href="slides.html">View Slides</a>
            <a href="assignment.html">Assignment</a>
        </div>

        <h2>ğŸ“š Overview / æ¦‚è¦</h2>
        <div class="bilingual">
            <div class="english">
                <p>This week dives deep into supervised learning, the most widely used machine learning paradigm. We'll explore regression and classification, understand the training process, and learn about model evaluation metrics. You'll gain hands-on understanding of how to build and assess predictive models.</p>
                <p><strong>Learning Objectives:</strong></p>
                <ul>
                    <li>Master the supervised learning workflow</li>
                    <li>Understand linear and logistic regression</li>
                    <li>Learn how to split data for training and testing</li>
                    <li>Evaluate model performance using appropriate metrics</li>
                    <li>Recognize overfitting and underfitting</li>
                    <li>Apply supervised learning to real-world problems</li>
                </ul>
            </div>
            <div class="japanese">
                <p>ä»Šé€±ã¯ã€æœ€ã‚‚åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã§ã‚ã‚‹æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚’æ·±ãæ˜ã‚Šä¸‹ã’ã¾ã™ã€‚å›å¸°ã¨åˆ†é¡ã‚’æ¢ã‚Šã€è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç†è§£ã—ã€ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™ã«ã¤ã„ã¦å­¦ã³ã¾ã™ã€‚äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨è©•ä¾¡ã«ã¤ã„ã¦å®Ÿè·µçš„ãªç†è§£ã‚’å¾—ã¾ã™ã€‚</p>
                <p><strong>å­¦ç¿’ç›®æ¨™:</strong></p>
                <ul>
                    <li>æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç¿’å¾—ã™ã‚‹</li>
                    <li>ç·šå½¢å›å¸°ã¨ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã‚’ç†è§£ã™ã‚‹</li>
                    <li>è¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿åˆ†å‰²æ–¹æ³•ã‚’å­¦ã¶</li>
                    <li>é©åˆ‡ãªæŒ‡æ¨™ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã™ã‚‹</li>
                    <li>éå­¦ç¿’ã¨æœªå­¦ç¿’ã‚’èªè­˜ã™ã‚‹</li>
                    <li>å®Ÿä¸–ç•Œã®å•é¡Œã«æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚’é©ç”¨ã™ã‚‹</li>
                </ul>
            </div>
        </div>

        <h2>1. The Supervised Learning Workflow</h2>
        <h2>æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</h2>

        <div class="definition-box">
            <h3>The Complete Process / å®Œå…¨ãªãƒ—ãƒ­ã‚»ã‚¹</h3>
            <div class="code-box">SUPERVISED LEARNING WORKFLOW
æ•™å¸«ã‚ã‚Šå­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

Step 1: COLLECT DATA (ãƒ‡ãƒ¼ã‚¿åé›†)
â”œâ”€ Gather labeled examples (X, Y pairs)
â””â”€ Ensure quality and relevance

Step 2: PREPARE DATA (ãƒ‡ãƒ¼ã‚¿æº–å‚™)
â”œâ”€ Clean data (handle missing values, outliers)
â”œâ”€ Feature engineering (create useful features)
â”œâ”€ Normalize/scale features
â””â”€ Split into train/test sets

Step 3: CHOOSE MODEL (ãƒ¢ãƒ‡ãƒ«é¸æŠ)
â”œâ”€ Regression or Classification?
â”œâ”€ Linear or Non-linear?
â””â”€ Simple or Complex?

Step 4: TRAIN MODEL (ãƒ¢ãƒ‡ãƒ«è¨“ç·´)
â”œâ”€ Feed training data to algorithm
â”œâ”€ Algorithm learns patterns
â””â”€ Adjust parameters to minimize error

Step 5: EVALUATE MODEL (ãƒ¢ãƒ‡ãƒ«è©•ä¾¡)
â”œâ”€ Test on unseen data
â”œâ”€ Calculate metrics (accuracy, error, etc.)
â””â”€ Compare to baseline

Step 6: TUNE & IMPROVE (èª¿æ•´ã¨æ”¹å–„)
â”œâ”€ Adjust hyperparameters
â”œâ”€ Try different algorithms
â””â”€ Add/remove features

Step 7: DEPLOY (ãƒ‡ãƒ—ãƒ­ã‚¤)
â””â”€ Use model in production</div>
        </div>

        <div class="bilingual">
            <div class="english">
                <h3>Data Splitting Strategy</h3>
                <p>A critical aspect of supervised learning is properly splitting your data to ensure reliable evaluation.</p>

                <h4>Training Set (è¨“ç·´ã‚»ãƒƒãƒˆ)</h4>
                <p><strong>Purpose:</strong> Used to train the model - the algorithm learns patterns from this data.</p>
                <p><strong>Typical Size:</strong> 70-80% of total data</p>
                <p><strong>Note:</strong> Model sees these examples during training</p>

                <h4>Test Set (ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ)</h4>
                <p><strong>Purpose:</strong> Used to evaluate final model performance - measures how well the model generalizes.</p>
                <p><strong>Typical Size:</strong> 20-30% of total data</p>
                <p><strong>Note:</strong> Model never sees these examples during training</p>

                <h4>Validation Set (Optional) (æ¤œè¨¼ã‚»ãƒƒãƒˆ)</h4>
                <p><strong>Purpose:</strong> Used for hyperparameter tuning and model selection.</p>
                <p><strong>Typical Split:</strong> 60% train, 20% validation, 20% test</p>
                <p><strong>Note:</strong> Helps prevent overfitting to test set</p>

                <h4>Why Split Data?</h4>
                <ul>
                    <li><strong>Prevent Overfitting:</strong> Testing on training data would be "cheating"</li>
                    <li><strong>Measure Generalization:</strong> See how model performs on new data</li>
                    <li><strong>Honest Evaluation:</strong> Get realistic performance estimates</li>
                    <li><strong>Model Selection:</strong> Compare different models fairly</li>
                </ul>
            </div>
            <div class="japanese">
                <h3>ãƒ‡ãƒ¼ã‚¿åˆ†å‰²æˆ¦ç•¥</h3>
                <p>æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®é‡è¦ãªå´é¢ã¯ã€ä¿¡é ¼ã§ãã‚‹è©•ä¾¡ã‚’ç¢ºå®Ÿã«ã™ã‚‹ãŸã‚ã«ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ã«åˆ†å‰²ã™ã‚‹ã“ã¨ã§ã™ã€‚</p>

                <h4>è¨“ç·´ã‚»ãƒƒãƒˆ (Training Set)</h4>
                <p><strong>ç›®çš„:</strong> ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ - ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã“ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã¾ã™ã€‚</p>
                <p><strong>ä¸€èˆ¬çš„ãªã‚µã‚¤ã‚º:</strong> ç·ãƒ‡ãƒ¼ã‚¿ã®70-80%</p>
                <p><strong>æ³¨:</strong> ãƒ¢ãƒ‡ãƒ«ã¯è¨“ç·´ä¸­ã«ã“ã‚Œã‚‰ã®ä¾‹ã‚’è¦‹ã¾ã™</p>

                <h4>ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ (Test Set)</h4>
                <p><strong>ç›®çš„:</strong> æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ - ãƒ¢ãƒ‡ãƒ«ãŒã©ã‚Œã ã‘ä¸€èˆ¬åŒ–ã™ã‚‹ã‹ã‚’æ¸¬å®šã—ã¾ã™ã€‚</p>
                <p><strong>ä¸€èˆ¬çš„ãªã‚µã‚¤ã‚º:</strong> ç·ãƒ‡ãƒ¼ã‚¿ã®20-30%</p>
                <p><strong>æ³¨:</strong> ãƒ¢ãƒ‡ãƒ«ã¯è¨“ç·´ä¸­ã«ã“ã‚Œã‚‰ã®ä¾‹ã‚’è¦‹ã¾ã›ã‚“</p>

                <h4>æ¤œè¨¼ã‚»ãƒƒãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰(Validation Set)</h4>
                <p><strong>ç›®çš„:</strong> ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã¨ãƒ¢ãƒ‡ãƒ«é¸æŠã«ä½¿ç”¨ã€‚</p>
                <p><strong>ä¸€èˆ¬çš„ãªåˆ†å‰²:</strong> 60%è¨“ç·´ã€20%æ¤œè¨¼ã€20%ãƒ†ã‚¹ãƒˆ</p>
                <p><strong>æ³¨:</strong> ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¸ã®éå­¦ç¿’ã‚’é˜²ãã®ã«å½¹ç«‹ã¡ã¾ã™</p>

                <h4>ãªãœãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã™ã‚‹ã®ã‹ï¼Ÿ</h4>
                <ul>
                    <li><strong>éå­¦ç¿’ã‚’é˜²ã:</strong> è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆã™ã‚‹ã®ã¯ã€Œã‚«ãƒ³ãƒ‹ãƒ³ã‚°ã€ã«ãªã‚Šã¾ã™</li>
                    <li><strong>ä¸€èˆ¬åŒ–ã‚’æ¸¬å®š:</strong> æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã™ã‚‹ã‹ã‚’ç¢ºèª</li>
                    <li><strong>æ­£ç›´ãªè©•ä¾¡:</strong> ç¾å®Ÿçš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¨å®šã‚’å–å¾—</li>
                    <li><strong>ãƒ¢ãƒ‡ãƒ«é¸æŠ:</strong> ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å…¬å¹³ã«æ¯”è¼ƒ</li>
                </ul>
            </div>
        </div>

        <h2>2. Linear Regression / ç·šå½¢å›å¸°</h2>

        <div class="definition-box">
            <h3>What is Linear Regression? / ç·šå½¢å›å¸°ã¨ã¯ï¼Ÿ</h3>
            <p><strong>Linear Regression:</strong> A supervised learning algorithm for predicting continuous numerical values by finding the best-fitting straight line through the data points.</p>
            <p><strong>ç·šå½¢å›å¸°:</strong> ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’é€šã‚‹æœ€é©ãªç›´ç·šã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€é€£ç¶šçš„ãªæ•°å€¤ã‚’äºˆæ¸¬ã™ã‚‹æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€‚</p>
        </div>

        <div class="bilingual">
            <div class="english">
                <h3>How Linear Regression Works</h3>

                <h4>The Mathematical Model</h4>
                <div class="code-box">Simple Linear Regression (1 feature):
y = mx + b

Where:
y = predicted value (output)
x = input feature
m = slope (weight)
b = y-intercept (bias)

Multiple Linear Regression (multiple features):
y = wâ‚xâ‚ + wâ‚‚xâ‚‚ + wâ‚ƒxâ‚ƒ + ... + b

Where:
y = predicted value
xâ‚, xâ‚‚, xâ‚ƒ = different features
wâ‚, wâ‚‚, wâ‚ƒ = weights for each feature
b = bias term</div>

                <h4>The Goal: Minimize Error</h4>
                <p>Linear regression finds the line that minimizes the difference between predicted and actual values.</p>

                <div class="code-box">Mean Squared Error (MSE):
MSE = (1/n) Ã— Î£(predicted - actual)Â²

Lower MSE = Better fit</div>

                <h4>Real-World Example: House Price Prediction</h4>
                <p><strong>Problem:</strong> Predict house price based on size</p>
                <ul>
                    <li><strong>Input (x):</strong> House size in square feet</li>
                    <li><strong>Output (y):</strong> Price in dollars</li>
                    <li><strong>Training:</strong> Learn from 1000 houses with known prices</li>
                    <li><strong>Model:</strong> Price = 200 Ã— Size + 50,000</li>
                    <li><strong>Prediction:</strong> 1,500 sq ft house = $350,000</li>
                </ul>

                <h4>Advantages:</h4>
                <ul>
                    <li>Simple and interpretable</li>
                    <li>Fast to train</li>
                    <li>Works well with linear relationships</li>
                    <li>Provides confidence intervals</li>
                </ul>

                <h4>Limitations:</h4>
                <ul>
                    <li>Assumes linear relationship</li>
                    <li>Sensitive to outliers</li>
                    <li>Cannot capture complex patterns</li>
                    <li>Features must be independent</li>
                </ul>
            </div>
            <div class="japanese">
                <h3>ç·šå½¢å›å¸°ã®ä»•çµ„ã¿</h3>

                <h4>æ•°å­¦çš„ãƒ¢ãƒ‡ãƒ«</h4>
                <div class="code-box">å˜ç´”ç·šå½¢å›å¸°ï¼ˆ1ã¤ã®ç‰¹å¾´é‡ï¼‰:
y = mx + b

ã“ã“ã§:
y = äºˆæ¸¬å€¤ï¼ˆå‡ºåŠ›ï¼‰
x = å…¥åŠ›ç‰¹å¾´é‡
m = å‚¾ãï¼ˆé‡ã¿ï¼‰
b = yåˆ‡ç‰‡ï¼ˆãƒã‚¤ã‚¢ã‚¹ï¼‰

é‡å›å¸°ï¼ˆè¤‡æ•°ã®ç‰¹å¾´é‡ï¼‰:
y = wâ‚xâ‚ + wâ‚‚xâ‚‚ + wâ‚ƒxâ‚ƒ + ... + b

ã“ã“ã§:
y = äºˆæ¸¬å€¤
xâ‚, xâ‚‚, xâ‚ƒ = ç•°ãªã‚‹ç‰¹å¾´é‡
wâ‚, wâ‚‚, wâ‚ƒ = å„ç‰¹å¾´é‡ã®é‡ã¿
b = ãƒã‚¤ã‚¢ã‚¹é …</div>

                <h4>ç›®æ¨™: ã‚¨ãƒ©ãƒ¼ã‚’æœ€å°åŒ–</h4>
                <p>ç·šå½¢å›å¸°ã¯ã€äºˆæ¸¬å€¤ã¨å®Ÿéš›ã®å€¤ã®å·®ã‚’æœ€å°åŒ–ã™ã‚‹ç›´ç·šã‚’è¦‹ã¤ã‘ã¾ã™ã€‚</p>

                <div class="code-box">å¹³å‡äºŒä¹—èª¤å·®ï¼ˆMSEï¼‰:
MSE = (1/n) Ã— Î£(äºˆæ¸¬å€¤ - å®Ÿéš›ã®å€¤)Â²

MSEãŒä½ã„ = ã‚ˆã‚Šè‰¯ã„ãƒ•ã‚£ãƒƒãƒˆ</div>

                <h4>å®Ÿä¸–ç•Œã®ä¾‹: ä½å®…ä¾¡æ ¼äºˆæ¸¬</h4>
                <p><strong>å•é¡Œ:</strong> ã‚µã‚¤ã‚ºã«åŸºã¥ã„ã¦ä½å®…ä¾¡æ ¼ã‚’äºˆæ¸¬</p>
                <ul>
                    <li><strong>å…¥åŠ›ï¼ˆxï¼‰:</strong> ä½å®…ã‚µã‚¤ã‚ºï¼ˆå¹³æ–¹ãƒ•ã‚£ãƒ¼ãƒˆï¼‰</li>
                    <li><strong>å‡ºåŠ›ï¼ˆyï¼‰:</strong> ä¾¡æ ¼ï¼ˆãƒ‰ãƒ«ï¼‰</li>
                    <li><strong>è¨“ç·´:</strong> æ—¢çŸ¥ã®ä¾¡æ ¼ã‚’æŒã¤1000è»’ã®ä½å®…ã‹ã‚‰å­¦ç¿’</li>
                    <li><strong>ãƒ¢ãƒ‡ãƒ«:</strong> ä¾¡æ ¼ = 200 Ã— ã‚µã‚¤ã‚º + 50,000</li>
                    <li><strong>äºˆæ¸¬:</strong> 1,500å¹³æ–¹ãƒ•ã‚£ãƒ¼ãƒˆã®ä½å®… = $350,000</li>
                </ul>

                <h4>åˆ©ç‚¹:</h4>
                <ul>
                    <li>ã‚·ãƒ³ãƒ—ãƒ«ã§è§£é‡ˆå¯èƒ½</li>
                    <li>è¨“ç·´ãŒé€Ÿã„</li>
                    <li>ç·šå½¢é–¢ä¿‚ã§ã†ã¾ãæ©Ÿèƒ½</li>
                    <li>ä¿¡é ¼åŒºé–“ã‚’æä¾›</li>
                </ul>

                <h4>åˆ¶é™:</h4>
                <ul>
                    <li>ç·šå½¢é–¢ä¿‚ã‚’ä»®å®š</li>
                    <li>å¤–ã‚Œå€¤ã«æ•æ„Ÿ</li>
                    <li>è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‰ã‚Œãªã„</li>
                    <li>ç‰¹å¾´é‡ã¯ç‹¬ç«‹ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚‹</li>
                </ul>
            </div>
        </div>

        <h2>3. Logistic Regression / ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°</h2>

        <div class="definition-box">
            <h3>What is Logistic Regression? / ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¨ã¯ï¼Ÿ</h3>
            <p><strong>Logistic Regression:</strong> A supervised learning algorithm for binary classification that predicts the probability of an instance belonging to a particular class.</p>
            <p><strong>ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°:</strong> ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒç‰¹å®šã®ã‚¯ãƒ©ã‚¹ã«å±ã™ã‚‹ç¢ºç‡ã‚’äºˆæ¸¬ã™ã‚‹äºŒå€¤åˆ†é¡ã®ãŸã‚ã®æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€‚</p>
        </div>

        <div class="bilingual">
            <div class="english">
                <h3>Understanding Logistic Regression</h3>

                <h4>Key Difference from Linear Regression</h4>
                <ul>
                    <li><strong>Linear Regression:</strong> Predicts continuous values (any number)</li>
                    <li><strong>Logistic Regression:</strong> Predicts probabilities (0 to 1) for classification</li>
                </ul>

                <h4>The Sigmoid Function</h4>
                <p>Logistic regression uses the sigmoid function to convert any value into a probability between 0 and 1.</p>

                <div class="code-box">Sigmoid Function:
Ïƒ(x) = 1 / (1 + e^(-x))

Output: Always between 0 and 1
Perfect for probability!

Decision Rule:
If Ïƒ(x) â‰¥ 0.5 â†’ Predict Class 1
If Ïƒ(x) < 0.5 â†’ Predict Class 0</div>

                <h4>Binary Classification Example: Email Spam Detection</h4>
                <p><strong>Problem:</strong> Classify emails as spam or not spam</p>
                <ul>
                    <li><strong>Features:</strong>
                        <ul>
                            <li>Number of exclamation marks</li>
                            <li>Presence of "free" or "winner"</li>
                            <li>Sender domain</li>
                            <li>Email length</li>
                        </ul>
                    </li>
                    <li><strong>Output:</strong> Probability of being spam (0 to 1)</li>
                    <li><strong>Decision:</strong> If probability > 0.5 â†’ Spam, else Not Spam</li>
                </ul>

                <h4>Multiclass Classification</h4>
                <p>Logistic regression can be extended to multiple classes:</p>
                <ul>
                    <li><strong>One-vs-Rest:</strong> Train one classifier per class</li>
                    <li><strong>Softmax Regression:</strong> Direct multiclass extension</li>
                    <li><strong>Example:</strong> Classifying images as cat, dog, or bird</li>
                </ul>
            </div>
            <div class="japanese">
                <h3>ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã®ç†è§£</h3>

                <h4>ç·šå½¢å›å¸°ã¨ã®ä¸»ãªé•ã„</h4>
                <ul>
                    <li><strong>ç·šå½¢å›å¸°:</strong> é€£ç¶šå€¤ã‚’äºˆæ¸¬ï¼ˆä»»æ„ã®æ•°ï¼‰</li>
                    <li><strong>ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°:</strong> åˆ†é¡ã®ãŸã‚ã®ç¢ºç‡ã‚’äºˆæ¸¬ï¼ˆ0ã‹ã‚‰1ï¼‰</li>
                </ul>

                <h4>ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°</h4>
                <p>ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¯ã€ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ä»»æ„ã®å€¤ã‚’0ã‹ã‚‰1ã®é–“ã®ç¢ºç‡ã«å¤‰æ›ã—ã¾ã™ã€‚</p>

                <div class="code-box">ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°:
Ïƒ(x) = 1 / (1 + e^(-x))

å‡ºåŠ›: å¸¸ã«0ã¨1ã®é–“
ç¢ºç‡ã«æœ€é©ï¼

æ±ºå®šãƒ«ãƒ¼ãƒ«:
Ïƒ(x) â‰¥ 0.5 â†’ ã‚¯ãƒ©ã‚¹1ã‚’äºˆæ¸¬
Ïƒ(x) < 0.5 â†’ ã‚¯ãƒ©ã‚¹0ã‚’äºˆæ¸¬</div>

                <h4>äºŒå€¤åˆ†é¡ã®ä¾‹: ãƒ¡ãƒ¼ãƒ«ã‚¹ãƒ‘ãƒ æ¤œå‡º</h4>
                <p><strong>å•é¡Œ:</strong> ãƒ¡ãƒ¼ãƒ«ã‚’ã‚¹ãƒ‘ãƒ ã‹éã‚¹ãƒ‘ãƒ ã«åˆ†é¡</p>
                <ul>
                    <li><strong>ç‰¹å¾´é‡:</strong>
                        <ul>
                            <li>æ„Ÿå˜†ç¬¦ã®æ•°</li>
                            <li>ã€Œç„¡æ–™ã€ã‚„ã€Œå½“é¸ã€ã®æœ‰ç„¡</li>
                            <li>é€ä¿¡è€…ãƒ‰ãƒ¡ã‚¤ãƒ³</li>
                            <li>ãƒ¡ãƒ¼ãƒ«ã®é•·ã•</li>
                        </ul>
                    </li>
                    <li><strong>å‡ºåŠ›:</strong> ã‚¹ãƒ‘ãƒ ã§ã‚ã‚‹ç¢ºç‡ï¼ˆ0ã‹ã‚‰1ï¼‰</li>
                    <li><strong>æ±ºå®š:</strong> ç¢ºç‡ > 0.5 â†’ ã‚¹ãƒ‘ãƒ ã€ãã‚Œä»¥å¤– éã‚¹ãƒ‘ãƒ </li>
                </ul>

                <h4>å¤šã‚¯ãƒ©ã‚¹åˆ†é¡</h4>
                <p>ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¯è¤‡æ•°ã‚¯ãƒ©ã‚¹ã«æ‹¡å¼µã§ãã¾ã™:</p>
                <ul>
                    <li><strong>One-vs-Rest:</strong> ã‚¯ãƒ©ã‚¹ã”ã¨ã«1ã¤ã®åˆ†é¡å™¨ã‚’è¨“ç·´</li>
                    <li><strong>ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°:</strong> ç›´æ¥çš„ãªå¤šã‚¯ãƒ©ã‚¹æ‹¡å¼µ</li>
                    <li><strong>ä¾‹:</strong> ç”»åƒã‚’çŒ«ã€çŠ¬ã€ã¾ãŸã¯é³¥ã«åˆ†é¡</li>
                </ul>
            </div>
        </div>

        <h2>4. Model Evaluation Metrics / ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™</h2>

        <div class="key-terms">
            <h3>Regression Metrics (å›å¸°æŒ‡æ¨™)</h3>
            <ul>
                <li><strong>Mean Squared Error (MSE) / å¹³å‡äºŒä¹—èª¤å·®:</strong> Average of squared differences between predicted and actual values. Lower is better.</li>
                <li><strong>Root Mean Squared Error (RMSE) / äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®:</strong> Square root of MSE. Same units as target variable.</li>
                <li><strong>Mean Absolute Error (MAE) / å¹³å‡çµ¶å¯¾èª¤å·®:</strong> Average of absolute differences. Less sensitive to outliers than MSE.</li>
                <li><strong>RÂ² Score (æ±ºå®šä¿‚æ•°):</strong> Proportion of variance explained by model. Range: 0 to 1, closer to 1 is better.</li>
            </ul>
        </div>

        <div class="key-terms">
            <h3>Classification Metrics (åˆ†é¡æŒ‡æ¨™)</h3>
            <ul>
                <li><strong>Accuracy / ç²¾åº¦:</strong> Percentage of correct predictions. Simple but can be misleading with imbalanced data.</li>
                <li><strong>Precision / é©åˆç‡:</strong> Of predicted positives, how many are truly positive? Important when false positives are costly.</li>
                <li><strong>Recall (Sensitivity) / å†ç¾ç‡:</strong> Of actual positives, how many did we find? Important when false negatives are costly.</li>
                <li><strong>F1 Score:</strong> Harmonic mean of precision and recall. Balances both metrics.</li>
                <li><strong>Confusion Matrix / æ··åŒè¡Œåˆ—:</strong> Table showing true positives, true negatives, false positives, false negatives.</li>
            </ul>
        </div>

        <div class="highlight-box">
            <h3>Understanding the Confusion Matrix</h3>
            <div class="code-box">                  PREDICTED
                 Positive  Negative
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
ACTUAL   P  â”‚   TP        â”‚   FN    â”‚  TP = True Positive (æ­£ã—ãé™½æ€§ã¨äºˆæ¸¬)
         o  â”‚  (Correct)  â”‚ (Miss)  â”‚  FN = False Negative (é™°æ€§ã¨èª¤äºˆæ¸¬)
         s  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         i  â”‚   FP        â”‚   TN    â”‚  FP = False Positive (é™½æ€§ã¨èª¤äºˆæ¸¬)
         t  â”‚ (False      â”‚(Correct)â”‚  TN = True Negative (æ­£ã—ãé™°æ€§ã¨äºˆæ¸¬)
         i  â”‚  Alarm)     â”‚         â”‚
         v  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         e

Accuracy  = (TP + TN) / Total
Precision = TP / (TP + FP)
Recall    = TP / (TP + FN)
F1 Score  = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)</div>

            <p><strong>Medical Diagnosis Example:</strong></p>
            <ul>
                <li><strong>TP:</strong> Patient has disease, test says positive (Correct)</li>
                <li><strong>TN:</strong> Patient healthy, test says negative (Correct)</li>
                <li><strong>FP:</strong> Patient healthy, test says positive (False alarm - causes anxiety)</li>
                <li><strong>FN:</strong> Patient has disease, test says negative (Dangerous - missed diagnosis)</li>
            </ul>
        </div>

        <h2>5. Overfitting and Underfitting / éå­¦ç¿’ã¨æœªå­¦ç¿’</h2>

        <div class="bilingual">
            <div class="english">
                <h3>Understanding the Bias-Variance Tradeoff</h3>

                <h4>Underfitting (High Bias) - æœªå­¦ç¿’</h4>
                <p><strong>Definition:</strong> Model is too simple to capture the underlying patterns in the data.</p>
                <p><strong>Signs:</strong></p>
                <ul>
                    <li>Poor performance on training data</li>
                    <li>Poor performance on test data</li>
                    <li>Model is too simple</li>
                </ul>
                <p><strong>Example:</strong> Using a straight line to fit clearly curved data</p>
                <p><strong>Solution:</strong></p>
                <ul>
                    <li>Use more complex model</li>
                    <li>Add more features</li>
                    <li>Reduce regularization</li>
                    <li>Train longer</li>
                </ul>

                <h4>Overfitting (High Variance) - éå­¦ç¿’</h4>
                <p><strong>Definition:</strong> Model learns training data too well, including noise and outliers, failing to generalize.</p>
                <p><strong>Signs:</strong></p>
                <ul>
                    <li>Excellent performance on training data</li>
                    <li>Poor performance on test data</li>
                    <li>Large gap between train and test accuracy</li>
                </ul>
                <p><strong>Example:</strong> Memorizing every training example instead of learning patterns</p>
                <p><strong>Solution:</strong></p>
                <ul>
                    <li>Get more training data</li>
                    <li>Simplify model (reduce complexity)</li>
                    <li>Use regularization</li>
                    <li>Remove irrelevant features</li>
                    <li>Use dropout (for neural networks)</li>
                    <li>Early stopping</li>
                </ul>

                <h4>The Sweet Spot: Good Fit</h4>
                <p><strong>Goal:</strong> Balance between underfitting and overfitting</p>
                <p><strong>Characteristics:</strong></p>
                <ul>
                    <li>Good performance on training data</li>
                    <li>Good performance on test data</li>
                    <li>Model generalizes well to new data</li>
                    <li>Captures true patterns without memorizing noise</li>
                </ul>
            </div>
            <div class="japanese">
                <h3>ãƒã‚¤ã‚¢ã‚¹-ãƒãƒªã‚¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®ç†è§£</h3>

                <h4>æœªå­¦ç¿’ï¼ˆé«˜ãƒã‚¤ã‚¢ã‚¹ï¼‰- Underfitting</h4>
                <p><strong>å®šç¾©:</strong> ãƒ¢ãƒ‡ãƒ«ãŒãƒ‡ãƒ¼ã‚¿ã®åŸºç¤ã¨ãªã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹ã«ã¯å˜ç´”ã™ãã‚‹ã€‚</p>
                <p><strong>å…†å€™:</strong></p>
                <ul>
                    <li>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæ‚ªã„</li>
                    <li>ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæ‚ªã„</li>
                    <li>ãƒ¢ãƒ‡ãƒ«ãŒå˜ç´”ã™ãã‚‹</li>
                </ul>
                <p><strong>ä¾‹:</strong> æ˜ã‚‰ã‹ã«æ›²ç·šã®ãƒ‡ãƒ¼ã‚¿ã«ç›´ç·šã‚’å½“ã¦ã¯ã‚ã‚‹</p>
                <p><strong>è§£æ±ºç­–:</strong></p>
                <ul>
                    <li>ã‚ˆã‚Šè¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨</li>
                    <li>ã‚ˆã‚Šå¤šãã®ç‰¹å¾´é‡ã‚’è¿½åŠ </li>
                    <li>æ­£å‰‡åŒ–ã‚’æ¸›ã‚‰ã™</li>
                    <li>ã‚ˆã‚Šé•·ãè¨“ç·´</li>
                </ul>

                <h4>éå­¦ç¿’ï¼ˆé«˜ãƒãƒªã‚¢ãƒ³ã‚¹ï¼‰- Overfitting</h4>
                <p><strong>å®šç¾©:</strong> ãƒ¢ãƒ‡ãƒ«ãŒãƒã‚¤ã‚ºã‚„å¤–ã‚Œå€¤ã‚’å«ã‚€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ˆãå­¦ç¿’ã—ã™ãã¦ã€ä¸€èˆ¬åŒ–ã«å¤±æ•—ã™ã‚‹ã€‚</p>
                <p><strong>å…†å€™:</strong></p>
                <ul>
                    <li>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹</li>
                    <li>ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æ‚ªã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹</li>
                    <li>è¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã®ç²¾åº¦ã®å¤§ããªã‚®ãƒ£ãƒƒãƒ—</li>
                </ul>
                <p><strong>ä¾‹:</strong> ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹ä»£ã‚ã‚Šã«ã™ã¹ã¦ã®è¨“ç·´ä¾‹ã‚’è¨˜æ†¶ã™ã‚‹</p>
                <p><strong>è§£æ±ºç­–:</strong></p>
                <ul>
                    <li>ã‚ˆã‚Šå¤šãã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—</li>
                    <li>ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡ç´ åŒ–ï¼ˆè¤‡é›‘ã•ã‚’æ¸›ã‚‰ã™ï¼‰</li>
                    <li>æ­£å‰‡åŒ–ã‚’ä½¿ç”¨</li>
                    <li>ç„¡é–¢ä¿‚ãªç‰¹å¾´é‡ã‚’å‰Šé™¤</li>
                    <li>ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’ä½¿ç”¨ï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç”¨ï¼‰</li>
                    <li>æ—©æœŸåœæ­¢</li>
                </ul>

                <h4>æœ€é©ç‚¹: è‰¯ã„ãƒ•ã‚£ãƒƒãƒˆ</h4>
                <p><strong>ç›®æ¨™:</strong> æœªå­¦ç¿’ã¨éå­¦ç¿’ã®ãƒãƒ©ãƒ³ã‚¹</p>
                <p><strong>ç‰¹æ€§:</strong></p>
                <ul>
                    <li>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®è‰¯ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹</li>
                    <li>ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è‰¯ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹</li>
                    <li>ãƒ¢ãƒ‡ãƒ«ãŒæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆãä¸€èˆ¬åŒ–</li>
                    <li>ãƒã‚¤ã‚ºã‚’è¨˜æ†¶ã›ãšã«çœŸã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹</li>
                </ul>
            </div>
        </div>

        <h2>6. Real-World Application / å®Ÿä¸–ç•Œã®å¿œç”¨</h2>

        <div class="highlight-box">
            <h3>Zillow: House Price Prediction</h3>
            <h4>Link: <a href="https://www.zillow.com" target="_blank">https://www.zillow.com</a></h4>

            <div class="bilingual">
                <div class="english">
                    <p><strong>Challenge:</strong> Accurately estimate the value of millions of homes across the United States.</p>

                    <p><strong>Supervised Learning Approach:</strong></p>
                    <ul>
                        <li><strong>Algorithm:</strong> Multiple regression models (including gradient boosting)</li>
                        <li><strong>Features Used:</strong>
                            <ul>
                                <li>Square footage (size of house)</li>
                                <li>Number of bedrooms and bathrooms</li>
                                <li>Location (zip code, neighborhood)</li>
                                <li>Year built and renovation history</li>
                                <li>Lot size</li>
                                <li>Recent sales of comparable homes</li>
                                <li>Tax assessment data</li>
                                <li>Market trends</li>
                            </ul>
                        </li>
                        <li><strong>Training Data:</strong> Millions of actual home sales with known prices</li>
                        <li><strong>Output:</strong> Zestimate - predicted home value</li>
                    </ul>

                    <p><strong>Model Evaluation:</strong></p>
                    <ul>
                        <li>Median error rate: ~2% in best markets</li>
                        <li>Continuous retraining with new sales data</li>
                        <li>A/B testing of model improvements</li>
                        <li>Transparency: Shows confidence interval for each estimate</li>
                    </ul>

                    <p><strong>Impact:</strong> Over 100 million Zestimates updated daily, helping millions of people make informed real estate decisions.</p>

                    <p><strong>Challenges:</strong></p>
                    <ul>
                        <li>Unique home features hard to quantify</li>
                        <li>Market volatility</li>
                        <li>Limited data in some areas</li>
                        <li>Seasonal variations</li>
                    </ul>
                </div>
                <div class="japanese">
                    <p><strong>èª²é¡Œ:</strong> ç±³å›½å…¨åœŸã®æ•°ç™¾ä¸‡ã®ä½å®…ã®ä¾¡å€¤ã‚’æ­£ç¢ºã«æ¨å®šã™ã‚‹ã€‚</p>

                    <p><strong>æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ:</strong></p>
                    <ul>
                        <li><strong>ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ :</strong> è¤‡æ•°ã®å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆå‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã‚’å«ã‚€ï¼‰</li>
                        <li><strong>ä½¿ç”¨ã•ã‚Œã‚‹ç‰¹å¾´é‡:</strong>
                            <ul>
                                <li>å¹³æ–¹ãƒ•ã‚£ãƒ¼ãƒˆï¼ˆä½å®…ã®ã‚µã‚¤ã‚ºï¼‰</li>
                                <li>å¯å®¤ã¨ãƒã‚¹ãƒ«ãƒ¼ãƒ ã®æ•°</li>
                                <li>å ´æ‰€ï¼ˆéƒµä¾¿ç•ªå·ã€è¿‘éš£åœ°åŸŸï¼‰</li>
                                <li>å»ºç¯‰å¹´ã¨æ”¹è£…å±¥æ­´</li>
                                <li>æ•·åœ°ã‚µã‚¤ã‚º</li>
                                <li>é¡ä¼¼ä½å®…ã®æœ€è¿‘ã®è²©å£²</li>
                                <li>ç¨å‹™è©•ä¾¡ãƒ‡ãƒ¼ã‚¿</li>
                                <li>å¸‚å ´å‹•å‘</li>
                            </ul>
                        </li>
                        <li><strong>è¨“ç·´ãƒ‡ãƒ¼ã‚¿:</strong> æ—¢çŸ¥ã®ä¾¡æ ¼ã‚’æŒã¤æ•°ç™¾ä¸‡ã®å®Ÿéš›ã®ä½å®…è²©å£²</li>
                        <li><strong>å‡ºåŠ›:</strong> Zestimate - äºˆæ¸¬ã•ã‚Œã‚‹ä½å®…ä¾¡å€¤</li>
                    </ul>

                    <p><strong>ãƒ¢ãƒ‡ãƒ«è©•ä¾¡:</strong></p>
                    <ul>
                        <li>ä¸­å¤®å€¤ã‚¨ãƒ©ãƒ¼ç‡: æœ€è‰¯ã®å¸‚å ´ã§ç´„2%</li>
                        <li>æ–°ã—ã„è²©å£²ãƒ‡ãƒ¼ã‚¿ã§ã®ç¶™ç¶šçš„ãªå†è¨“ç·´</li>
                        <li>ãƒ¢ãƒ‡ãƒ«æ”¹å–„ã®A/Bãƒ†ã‚¹ãƒˆ</li>
                        <li>é€æ˜æ€§: å„æ¨å®šå€¤ã®ä¿¡é ¼åŒºé–“ã‚’è¡¨ç¤º</li>
                    </ul>

                    <p><strong>å½±éŸ¿:</strong> 1å„„ä»¥ä¸Šã®ZestimateãŒæ¯æ—¥æ›´æ–°ã•ã‚Œã€æ•°ç™¾ä¸‡äººãŒæƒ…å ±ã«åŸºã¥ã„ãŸä¸å‹•ç”£ã®æ±ºå®šã‚’ä¸‹ã™ã®ã‚’æ”¯æ´ã—ã¦ã„ã¾ã™ã€‚</p>

                    <p><strong>èª²é¡Œ:</strong></p>
                    <ul>
                        <li>å®šé‡åŒ–ãŒé›£ã—ã„ç‹¬è‡ªã®ä½å®…ç‰¹å¾´</li>
                        <li>å¸‚å ´ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£</li>
                        <li>ä¸€éƒ¨åœ°åŸŸã§ã®ãƒ‡ãƒ¼ã‚¿ä¸è¶³</li>
                        <li>å­£ç¯€å¤‰å‹•</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="study-tip">
            <h3>Study Tips for Supervised Learning</h3>
            <ul>
                <li>Understand the complete workflow from data to deployment</li>
                <li>Know when to use linear regression vs logistic regression</li>
                <li>Practice calculating metrics from a confusion matrix</li>
                <li>Be able to explain overfitting and underfitting with examples</li>
                <li>Understand why we split data into train/test sets</li>
                <li>Know the difference between regression and classification metrics</li>
                <li>Practice explaining concepts in both English and Japanese</li>
            </ul>
        </div>

        <h2>ğŸ“ Test Questions / ãƒ†ã‚¹ãƒˆå•é¡Œ</h2>

        <div class="test-question">
            <h4>TEST QUESTION 1: Multiple Choice</h4>
            <p><strong>What is the primary purpose of splitting data into training and test sets?</strong></p>
            <ol type="A">
                <li>To reduce the amount of data the model needs to process</li>
                <li>To evaluate how well the model generalizes to new, unseen data</li>
                <li>To make the training process faster</li>
                <li>To increase the accuracy on the training data</li>
            </ol>
            <p><strong>Answer:</strong> B - The test set allows us to evaluate model performance on data it has never seen, measuring generalization ability.</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 2: Multiple Choice</h4>
            <p><strong>Which algorithm should you use to predict the selling price of a used car?</strong></p>
            <ol type="A">
                <li>K-means clustering</li>
                <li>Linear regression</li>
                <li>Logistic regression</li>
                <li>Reinforcement learning</li>
            </ol>
            <p><strong>Answer:</strong> B - Linear regression is used for predicting continuous numerical values like prices.</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 3: Multiple Choice</h4>
            <p><strong>What does the sigmoid function in logistic regression do?</strong></p>
            <ol type="A">
                <li>Calculates the error rate</li>
                <li>Converts any value into a probability between 0 and 1</li>
                <li>Splits the data into training and test sets</li>
                <li>Finds the best features to use</li>
            </ol>
            <p><strong>Answer:</strong> B - The sigmoid function maps any input value to an output between 0 and 1, perfect for probability predictions.</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 4: Multiple Choice</h4>
            <p><strong>A model performs very well on training data (98% accuracy) but poorly on test data (65% accuracy). What is this called?</strong></p>
            <ol type="A">
                <li>Underfitting</li>
                <li>Overfitting</li>
                <li>Good generalization</li>
                <li>Perfect fit</li>
            </ol>
            <p><strong>Answer:</strong> B - Overfitting occurs when a model learns the training data too well and fails to generalize to new data.</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 5: Multiple Choice</h4>
            <p><strong>In a medical diagnosis system, which metric is most important when missing a disease (false negative) is very dangerous?</strong></p>
            <ol type="A">
                <li>Accuracy</li>
                <li>Precision</li>
                <li>Recall</li>
                <li>F1 Score</li>
            </ol>
            <p><strong>Answer:</strong> C - Recall measures how many actual positives we found. High recall means fewer false negatives (missed diseases).</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 6: Short Answer</h4>
            <p><strong>Explain the difference between linear regression and logistic regression. When would you use each?</strong></p>
            <p><strong>Sample Answer:</strong></p>
            <p><strong>Linear Regression:</strong></p>
            <ul>
                <li>Predicts continuous numerical values</li>
                <li>Output can be any number</li>
                <li>Example: Predicting house prices, temperature, stock prices</li>
                <li>Uses: y = mx + b formula</li>
            </ul>
            <p><strong>Logistic Regression:</strong></p>
            <ul>
                <li>Predicts probabilities for classification</li>
                <li>Output is between 0 and 1</li>
                <li>Example: Spam/not spam, disease/healthy, pass/fail</li>
                <li>Uses: Sigmoid function to convert to probability</li>
            </ul>
            <p>Use linear regression for regression problems (predicting quantities) and logistic regression for classification problems (predicting categories).</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 7: Short Answer</h4>
            <p><strong>Calculate precision, recall, and accuracy from this confusion matrix:</strong></p>
            <div class="code-box">              Predicted
            Spam  Not Spam
Actual Spam     80      20
       Not Spam 10      90</div>
            <p><strong>Sample Answer:</strong></p>
            <p>TP = 80, FN = 20, FP = 10, TN = 90</p>
            <p><strong>Accuracy</strong> = (TP + TN) / Total = (80 + 90) / 200 = 170/200 = 0.85 = 85%</p>
            <p><strong>Precision</strong> = TP / (TP + FP) = 80 / (80 + 10) = 80/90 = 0.889 = 88.9%</p>
            <p><strong>Recall</strong> = TP / (TP + FN) = 80 / (80 + 20) = 80/100 = 0.80 = 80%</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 8: Short Answer</h4>
            <p><strong>Describe three solutions to prevent overfitting in a supervised learning model.</strong></p>
            <p><strong>Sample Answer:</strong></p>
            <ol>
                <li><strong>Get More Training Data:</strong> With more examples, the model is less likely to memorize specific instances and will learn general patterns instead.</li>
                <li><strong>Use Regularization:</strong> Add penalties for model complexity to prevent it from fitting noise. This keeps the model simpler and more generalizable.</li>
                <li><strong>Remove Irrelevant Features:</strong> Feature selection helps by eliminating features that don't contribute to predictions, reducing the chance of learning spurious correlations.</li>
            </ol>
            <p>Other valid solutions: Cross-validation, early stopping, dropout (for neural networks), ensemble methods, or reducing model complexity.</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 9: Application Question</h4>
            <p><strong>Zillow uses supervised learning to predict house prices. Describe:</strong></p>
            <p><strong>a) What type of supervised learning problem is this (classification or regression)?</strong></p>
            <p><strong>b) List five features Zillow might use</strong></p>
            <p><strong>c) What would be the training data?</strong></p>
            <p><strong>d) What metric would be best to evaluate the model?</strong></p>
            <p><strong>Sample Answer:</strong></p>
            <p><strong>a) Type:</strong> Regression problem - predicting continuous numerical values (home prices)</p>
            <p><strong>b) Five features:</strong></p>
            <ol>
                <li>Square footage (house size)</li>
                <li>Number of bedrooms and bathrooms</li>
                <li>Location (zip code/neighborhood)</li>
                <li>Year built</li>
                <li>Recent comparable sales</li>
            </ol>
            <p><strong>c) Training data:</strong> Historical home sales with actual selling prices - millions of homes with known sale prices serve as labeled examples</p>
            <p><strong>d) Best metric:</strong> RMSE (Root Mean Squared Error) or MAE (Mean Absolute Error) because they measure prediction error in dollars, making it easy to understand. RÂ² score is also useful to show how much variance is explained.</p>
        </div>

        <div class="test-question">
            <h4>TEST QUESTION 10: Essay Question</h4>
            <p><strong>Explain the complete supervised learning workflow from data collection to deployment. For each step, describe what happens and why it's important. Use a real-world example (like spam detection or house price prediction) to illustrate.</strong></p>
            <p><strong>Sample Answer:</strong></p>
            <p><strong>Example: Email Spam Detection System</strong></p>

            <p><strong>Step 1: Data Collection</strong></p>
            <p>Gather labeled email examples - thousands of emails marked as "spam" or "not spam". This is crucial because supervised learning requires labeled data to learn from. Without quality labeled data, the model cannot learn accurate patterns.</p>

            <p><strong>Step 2: Data Preparation</strong></p>
            <p>Clean the data (remove duplicates, handle missing values), extract features (word counts, sender domain, presence of links, number of exclamation marks), and normalize features. Split data 80% training, 20% testing. This ensures the model receives high-quality, consistent input.</p>

            <p><strong>Step 3: Choose Model</strong></p>
            <p>Select logistic regression for binary classification (spam vs. not spam). The choice depends on the problem type - classification needs different algorithms than regression.</p>

            <p><strong>Step 4: Train Model</strong></p>
            <p>Feed training data (80%) to the logistic regression algorithm. It learns patterns like "emails with 'free winner' and many exclamation marks are likely spam". The model adjusts its parameters to minimize classification errors.</p>

            <p><strong>Step 5: Evaluate Model</strong></p>
            <p>Test on the held-out 20% of data the model has never seen. Calculate metrics: accuracy (overall correctness), precision (of emails marked spam, how many truly are), and recall (of actual spam, how much did we catch). This reveals if the model generalizes well.</p>

            <p><strong>Step 6: Tune & Improve</strong></p>
            <p>If performance is poor, adjust hyperparameters, try different features, or use different algorithms. If overfitting (high training accuracy, low test accuracy), add regularization or get more data. Iterate until satisfactory performance.</p>

            <p><strong>Step 7: Deploy</strong></p>
            <p>Integrate the model into email systems to automatically filter spam in real-time. Monitor performance and retrain periodically with new data as spam patterns evolve.</p>

            <p><strong>Importance:</strong> Following this systematic workflow ensures reliable, well-tested models that actually work in production, rather than just performing well in development.</p>
        </div>

        <h2>ğŸ¯ Key Takeaways / é‡è¦ãƒã‚¤ãƒ³ãƒˆ</h2>

        <div class="highlight-box">
            <h3>Remember These Core Concepts:</h3>
            <ul>
                <li><strong>Supervised Learning Workflow:</strong> Collect â†’ Prepare â†’ Choose â†’ Train â†’ Evaluate â†’ Tune â†’ Deploy</li>
                <li><strong>Data Splitting:</strong> 70-80% train, 20-30% test (never test on training data!)</li>
                <li><strong>Linear Regression:</strong> Predicts continuous values (y = mx + b)</li>
                <li><strong>Logistic Regression:</strong> Predicts probabilities for classification (uses sigmoid function)</li>
                <li><strong>Overfitting:</strong> Great on training, poor on test â†’ Need more data or simpler model</li>
                <li><strong>Underfitting:</strong> Poor on both â†’ Need more complex model or better features</li>
                <li><strong>Classification Metrics:</strong> Accuracy, Precision, Recall, F1 Score</li>
                <li><strong>Regression Metrics:</strong> MSE, RMSE, MAE, RÂ² Score</li>
            </ul>
        </div>

        <div class="navigation">
            <a href="../../index.html">â† Course Home</a>
            <a href="../week-09/lecture.html">â† Previous Week</a>
            <a href="slides.html">View Slides</a>
            <a href="assignment.html">Assignment</a>
            <a href="../week-11/lecture.html">Next Week â†’</a>
        </div>

        <footer style="margin-top: 50px; padding-top: 20px; border-top: 2px solid #e5e7eb; text-align: center; color: #666;">
            <p>Week 10 Lecture Notes - Introduction to AI and Data Science</p>
            <p>Chukyo University - 2025</p>
        </footer>
    </div>
</body>
</html>